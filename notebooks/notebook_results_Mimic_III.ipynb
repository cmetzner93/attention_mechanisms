{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3f8aa61e",
   "metadata": {},
   "source": [
    "# Attention Mechanisms in Clinical Text Classification: A Comparative Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93877af4",
   "metadata": {},
   "source": [
    "# Results on MIMIC-III"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5f35342e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "# built-in libraries\n",
    "import os\n",
    "import sys\n",
    "import pickle\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "from typing import List\n",
    "\n",
    "try:\n",
    "    root = os.path.dirname(os.path.dirname(os.path.abspath(__file__)))\n",
    "except NameError:\n",
    "    root = os.path.dirname(os.getcwd())\n",
    "sys.path.append(root)\n",
    "\n",
    "# installed libraries\n",
    "import numpy as np\n",
    "np.random.seed(42)\n",
    "import scipy.stats as st\n",
    "\n",
    "import pandas as pd\n",
    "pd.set_option('display.max_rows', None)\n",
    "pd.set_option('display.max_columns', None)\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.patches import Patch\n",
    "\n",
    "# Set path to results\n",
    "path_results = os.path.join(root, 'results')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8a570a6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ci_95(x: np.array, ci: float = 0.95) -> float:\n",
    "    \"\"\"\n",
    "    Function that calculates the confidence interval for a given array\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    x : np.array\n",
    "        Array of floats\n",
    "    ci : float; default=0.95\n",
    "        confidence level\n",
    "    \"\"\"\n",
    "    cint_95 = st.t.interval(ci, len(x)-1, loc=np.mean(x), scale=st.sem(x))\n",
    "    return cint_95[1] - np.mean(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "112594f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_xdeltas_barplot(width: float = 1, gap_width: float = 1.5, n_bars = 6) -> List[float]:\n",
    "    \"\"\"\n",
    "    Function that computes offset values for barplot placements. The barplot is expected to show two related values\n",
    "    right next to eather other.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    width : float; default = 1\n",
    "        Expected witdh of bar in barplot\n",
    "    gap_width : float; default = 1.5\n",
    "        Expected width between bars in barplot\n",
    "    n_bars : int; default = 6\n",
    "        Number of bar sub-positions per X coordinate \n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "    x_pos_micros : List[float]\n",
    "        List containing offset values for micro F1-scores\n",
    "    x_pos_macros : List[float]\n",
    "        List containing offset values for macro F1-scores\n",
    "        \n",
    "    \"\"\"\n",
    "    # Get sub-positions\n",
    "    \n",
    "    helper_arr = np.arange(n_bars / 2 * (-1), n_bars / 2 + 1, 1, dtype=int)\n",
    "    ns = list(helper_arr[helper_arr != 0])\n",
    "    \n",
    "    x_pos_micros = []\n",
    "    x_pos_macros = []\n",
    "    for n in ns:\n",
    "        if n < 0:\n",
    "            pos = n * width + gap_width * (n + 1) - 0.5 * gap_width\n",
    "        elif n > 0:\n",
    "            if n == 1:\n",
    "                pos = 0.5 * gap_width\n",
    "            else:\n",
    "                pos = 0.5 * gap_width + (n - 1) * width + (n - 1) * gap_width\n",
    "\n",
    "\n",
    "        x_pos_micros.append(round(pos, 1))\n",
    "        x_pos_macros.append(round(pos + 1,1 ))\n",
    "        \n",
    "    print(f'x_pos_micros: {x_pos_micros}')\n",
    "    print(f'x_pos_macros: {x_pos_macros}')\n",
    "\n",
    "    return x_pos_micros, x_pos_macros"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2408fe2",
   "metadata": {},
   "source": [
    "# Results Section A: MIMIC-III-Full\n",
    "\n",
    "This section shows the following results:\n",
    "- Overall\n",
    "- Quartile Performance"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e29b7d1e",
   "metadata": {},
   "source": [
    "## Results: MIMIC-III-Full - Overall\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "daeb320a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Key variables\n",
    "averages = ['micro', 'macro']\n",
    "models = ['CNN', 'BiGRU', 'BiLSTM', 'CLF']\n",
    "atts = ['baseline', 'target', 'random', 'pretrained', 'hierarchical_random', 'hierarchical_pretrained']\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "deef7749",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>att_module</th>\n",
       "      <th>f1_macro_sk_mean</th>\n",
       "      <th>f1_macro_sk_ci_95</th>\n",
       "      <th>f1_micro_sk_mean</th>\n",
       "      <th>f1_micro_sk_ci_95</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>BiGRU</td>\n",
       "      <td>baseline</td>\n",
       "      <td>0.03020</td>\n",
       "      <td>0.002388</td>\n",
       "      <td>0.435200</td>\n",
       "      <td>0.008018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>BiGRU</td>\n",
       "      <td>hierarchical_pretrained</td>\n",
       "      <td>0.06140</td>\n",
       "      <td>0.003787</td>\n",
       "      <td>0.533200</td>\n",
       "      <td>0.003766</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>BiGRU</td>\n",
       "      <td>hierarchical_random</td>\n",
       "      <td>0.05760</td>\n",
       "      <td>0.007481</td>\n",
       "      <td>0.525800</td>\n",
       "      <td>0.006233</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>BiGRU</td>\n",
       "      <td>pretrained</td>\n",
       "      <td>0.06220</td>\n",
       "      <td>0.005297</td>\n",
       "      <td>0.534600</td>\n",
       "      <td>0.005089</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>BiGRU</td>\n",
       "      <td>random</td>\n",
       "      <td>0.06000</td>\n",
       "      <td>0.007240</td>\n",
       "      <td>0.530800</td>\n",
       "      <td>0.006108</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>BiGRU</td>\n",
       "      <td>target</td>\n",
       "      <td>0.03360</td>\n",
       "      <td>0.005089</td>\n",
       "      <td>0.437400</td>\n",
       "      <td>0.009481</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>BiLSTM</td>\n",
       "      <td>baseline</td>\n",
       "      <td>0.02340</td>\n",
       "      <td>0.001416</td>\n",
       "      <td>0.377400</td>\n",
       "      <td>0.006488</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>BiLSTM</td>\n",
       "      <td>hierarchical_pretrained</td>\n",
       "      <td>0.06100</td>\n",
       "      <td>0.008954</td>\n",
       "      <td>0.536800</td>\n",
       "      <td>0.008709</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>BiLSTM</td>\n",
       "      <td>hierarchical_random</td>\n",
       "      <td>0.05500</td>\n",
       "      <td>0.005757</td>\n",
       "      <td>0.522400</td>\n",
       "      <td>0.010186</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>BiLSTM</td>\n",
       "      <td>pretrained</td>\n",
       "      <td>0.06040</td>\n",
       "      <td>0.008980</td>\n",
       "      <td>0.537400</td>\n",
       "      <td>0.007481</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>BiLSTM</td>\n",
       "      <td>random</td>\n",
       "      <td>0.06080</td>\n",
       "      <td>0.006476</td>\n",
       "      <td>0.538000</td>\n",
       "      <td>0.007079</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>BiLSTM</td>\n",
       "      <td>target</td>\n",
       "      <td>0.02880</td>\n",
       "      <td>0.003556</td>\n",
       "      <td>0.381400</td>\n",
       "      <td>0.010810</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>CLF</td>\n",
       "      <td>baseline</td>\n",
       "      <td>0.02225</td>\n",
       "      <td>0.000796</td>\n",
       "      <td>0.383250</td>\n",
       "      <td>0.009312</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>CLF</td>\n",
       "      <td>hierarchical_pretrained</td>\n",
       "      <td>0.06340</td>\n",
       "      <td>0.015424</td>\n",
       "      <td>0.551800</td>\n",
       "      <td>0.022409</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>CLF</td>\n",
       "      <td>hierarchical_random</td>\n",
       "      <td>0.02100</td>\n",
       "      <td>0.010828</td>\n",
       "      <td>0.358667</td>\n",
       "      <td>0.075115</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>CLF</td>\n",
       "      <td>pretrained</td>\n",
       "      <td>0.06300</td>\n",
       "      <td>0.015877</td>\n",
       "      <td>0.549800</td>\n",
       "      <td>0.021567</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>CLF</td>\n",
       "      <td>random</td>\n",
       "      <td>0.05160</td>\n",
       "      <td>0.021174</td>\n",
       "      <td>0.524000</td>\n",
       "      <td>0.057974</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>CLF</td>\n",
       "      <td>target</td>\n",
       "      <td>0.02620</td>\n",
       "      <td>0.003332</td>\n",
       "      <td>0.406800</td>\n",
       "      <td>0.018130</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>CNN</td>\n",
       "      <td>baseline</td>\n",
       "      <td>0.01880</td>\n",
       "      <td>0.002221</td>\n",
       "      <td>0.378600</td>\n",
       "      <td>0.008629</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>CNN</td>\n",
       "      <td>hierarchical_pretrained</td>\n",
       "      <td>0.04520</td>\n",
       "      <td>0.023533</td>\n",
       "      <td>0.455200</td>\n",
       "      <td>0.056105</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>CNN</td>\n",
       "      <td>hierarchical_random</td>\n",
       "      <td>0.01180</td>\n",
       "      <td>0.005784</td>\n",
       "      <td>0.317800</td>\n",
       "      <td>0.038745</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>CNN</td>\n",
       "      <td>pretrained</td>\n",
       "      <td>0.04820</td>\n",
       "      <td>0.008665</td>\n",
       "      <td>0.488800</td>\n",
       "      <td>0.009350</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>CNN</td>\n",
       "      <td>random</td>\n",
       "      <td>0.03800</td>\n",
       "      <td>0.012754</td>\n",
       "      <td>0.469800</td>\n",
       "      <td>0.024051</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>CNN</td>\n",
       "      <td>target</td>\n",
       "      <td>0.02660</td>\n",
       "      <td>0.003238</td>\n",
       "      <td>0.350400</td>\n",
       "      <td>0.010374</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     model               att_module  f1_macro_sk_mean  f1_macro_sk_ci_95  \\\n",
       "0    BiGRU                 baseline           0.03020           0.002388   \n",
       "1    BiGRU  hierarchical_pretrained           0.06140           0.003787   \n",
       "2    BiGRU      hierarchical_random           0.05760           0.007481   \n",
       "3    BiGRU               pretrained           0.06220           0.005297   \n",
       "4    BiGRU                   random           0.06000           0.007240   \n",
       "5    BiGRU                   target           0.03360           0.005089   \n",
       "6   BiLSTM                 baseline           0.02340           0.001416   \n",
       "7   BiLSTM  hierarchical_pretrained           0.06100           0.008954   \n",
       "8   BiLSTM      hierarchical_random           0.05500           0.005757   \n",
       "9   BiLSTM               pretrained           0.06040           0.008980   \n",
       "10  BiLSTM                   random           0.06080           0.006476   \n",
       "11  BiLSTM                   target           0.02880           0.003556   \n",
       "12     CLF                 baseline           0.02225           0.000796   \n",
       "13     CLF  hierarchical_pretrained           0.06340           0.015424   \n",
       "14     CLF      hierarchical_random           0.02100           0.010828   \n",
       "15     CLF               pretrained           0.06300           0.015877   \n",
       "16     CLF                   random           0.05160           0.021174   \n",
       "17     CLF                   target           0.02620           0.003332   \n",
       "18     CNN                 baseline           0.01880           0.002221   \n",
       "19     CNN  hierarchical_pretrained           0.04520           0.023533   \n",
       "20     CNN      hierarchical_random           0.01180           0.005784   \n",
       "21     CNN               pretrained           0.04820           0.008665   \n",
       "22     CNN                   random           0.03800           0.012754   \n",
       "23     CNN                   target           0.02660           0.003238   \n",
       "\n",
       "    f1_micro_sk_mean  f1_micro_sk_ci_95  \n",
       "0           0.435200           0.008018  \n",
       "1           0.533200           0.003766  \n",
       "2           0.525800           0.006233  \n",
       "3           0.534600           0.005089  \n",
       "4           0.530800           0.006108  \n",
       "5           0.437400           0.009481  \n",
       "6           0.377400           0.006488  \n",
       "7           0.536800           0.008709  \n",
       "8           0.522400           0.010186  \n",
       "9           0.537400           0.007481  \n",
       "10          0.538000           0.007079  \n",
       "11          0.381400           0.010810  \n",
       "12          0.383250           0.009312  \n",
       "13          0.551800           0.022409  \n",
       "14          0.358667           0.075115  \n",
       "15          0.549800           0.021567  \n",
       "16          0.524000           0.057974  \n",
       "17          0.406800           0.018130  \n",
       "18          0.378600           0.008629  \n",
       "19          0.455200           0.056105  \n",
       "20          0.317800           0.038745  \n",
       "21          0.488800           0.009350  \n",
       "22          0.469800           0.024051  \n",
       "23          0.350400           0.010374  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load results data\n",
    "df_full = pd.read_excel(os.path.join(path_results, 'results_section_A', 'MimicFull_scores_final.xlsx')).drop(['Unnamed: 0'], axis=1)\n",
    "# Group data based on model and attention or baseline method\n",
    "df_full_grp = df_full.groupby(['Model', 'att_module'])[['f1_macro_sk', 'f1_micro_sk']].agg(['mean', ci_95]).reset_index()\n",
    "# Remove multi-level column indexing and corrent column naming\n",
    "df_full_grp.columns = df_full_grp.columns.map('{0[0]}_{0[1]}'.format)\n",
    "df_full_grp = df_full_grp.rename(columns={\"Model_\": \"model\", \"att_module_\": \"att_module\"})\n",
    "df_full_grp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4f60e39e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_pos_micros: [-6.8, -4.2, -1.8, 0.8, 3.2, 5.8]\n",
      "x_pos_macros: [-5.8, -3.2, -0.8, 1.8, 4.2, 6.8]\n",
      "\n",
      "Visualize results for MIMIC-III-Full:\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x576 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "width = 1\n",
    "# Visualize scores\n",
    "fig, ax = plt.subplots(figsize=(10, 8), facecolor='white')\n",
    "\n",
    "# Scale X-positions - impacts proximity between the bars of different text-encoder architectures\n",
    "X = np.arange(len(models)) * 18\n",
    "x_pos_micros, x_pos_macros = get_xdeltas_barplot(width=width, gap_width=1.5, n_bars=6)\n",
    "\n",
    "# Color scale\n",
    "colors = sns.color_palette('colorblind').as_hex()[:len(atts)]\n",
    "\n",
    "# We are plotting the micro and macro F1-scores right next to each other\n",
    "for average in averages:\n",
    "    # F1-score averages have different offset values\n",
    "    if average == 'micro':\n",
    "        x_deltas = x_pos_micros\n",
    "    elif average == 'macro':\n",
    "        x_deltas = x_pos_macros\n",
    "    \n",
    "    # Loop through considered text-encoder architectures (i.e., models)\n",
    "    # Each model has its own primary x-coordinate\n",
    "    for x, model in zip(X, models):\n",
    "        df_model = df_full_grp[df_full_grp['model']==model]\n",
    "        \n",
    "        # Loop through baseline and attention mechanisms list\n",
    "        # Each method has its own offset\n",
    "        # Each method has its own color\n",
    "        for c, (x_delta, att) in enumerate(zip(x_deltas, atts)):\n",
    "            # Get values from dataframe\n",
    "            height = df_model[df_model['att_module']==att][f'f1_{average}_sk_mean']\n",
    "            err = df_model[df_model['att_module']==att][f'f1_{average}_sk_ci_95']\n",
    "\n",
    "            # Plot results\n",
    "            if average == 'macro':\n",
    "                plt.bar(x = x + x_delta, height=height, yerr=err,\n",
    "                        color=colors[c], edgecolor='k',\n",
    "                        width=width, hatch='\\\\\\\\\\\\\\\\', align='edge', zorder=3,\n",
    "                        error_kw=dict(lw=2, capsize=3, capthick=1.5, ecolor='k'))\n",
    "            else:\n",
    "                plt.bar(x = x + x_delta, height=height, yerr=err,\n",
    "                        color=colors[c], edgecolor='k',\n",
    "                        width=width, align='edge', zorder=3,\n",
    "                        error_kw=dict(lw=2, capsize=3, capthick=1.5, ecolor='k'))\n",
    "                \n",
    "# Add descriptions and corrext axis\n",
    "ax.set_xticks(X+0.25)\n",
    "xlabels = ['CNN', 'Bi-GRU', 'Bi-LSTM', 'CLF']\n",
    "ax.set_xticklabels(xlabels, fontsize=24)\n",
    "\n",
    "\n",
    "ax.set_yticklabels([0, 0.1, 0.2, 0.3, 0.4, 0.5, 0.6], fontsize=18)\n",
    "ax.set_ylim(0, 0.6)\n",
    "\n",
    "#plt.xlabel('Text Encoder Architecture', fontsize=18)\n",
    "plt.xlabel('')\n",
    "plt.ylabel('F1-Score', fontsize=24)\n",
    "\n",
    "ax.spines.right.set_visible(False)\n",
    "ax.spines.left.set_visible(False)\n",
    "ax.spines.top.set_visible(False)\n",
    "\n",
    "fig.tight_layout()\n",
    "plt.grid( which='major', axis='y', zorder=0)\n",
    "plt.tick_params(left = False)\n",
    "\n",
    "# generate legend\n",
    "xlabels = ['Architecture-Specific Baseline', 'Target-Attention', \n",
    "                    'Random Label-Attention', 'Pretrained Label-Attention',\n",
    "                    'Hierarchical Random Label-Attention', 'Hierarchical Pretrained Label-Attention']\n",
    "legend_elements = []\n",
    "\n",
    "for color, label in zip(colors, xlabels):\n",
    "    patch = Patch(facecolor=color, label=label, edgecolor='k')\n",
    "    legend_elements.append(patch)\n",
    "\n",
    "legend_elements.append(Patch(label='Macro-Average', hatch='\\\\\\\\\\\\\\\\', edgecolor='k', facecolor='none', linewidth=1))\n",
    "legend_elements.append(Patch(label='Micro-Average', hatch=None, edgecolor='k', facecolor='none', linewidth=1))\n",
    "\n",
    "plt.legend(loc='lower center', fontsize=16, ncol=2, frameon=False, bbox_to_anchor=(0.5,-0.28),\n",
    "          handles=legend_elements)\n",
    "\n",
    "print('\\nVisualize results for MIMIC-III-Full:\\n')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d028fa1",
   "metadata": {},
   "source": [
    "## Results: MIMIC-III-Full - Quartile Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8cf9b4b3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>Q2</th>\n",
       "      <th>Q3</th>\n",
       "      <th>Q4</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Model</th>\n",
       "      <th>att_module</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"6\" valign=\"top\">BiGRU</th>\n",
       "      <th>baseline</th>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.012400</td>\n",
       "      <td>0.45120</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hierarchical_pretrained</th>\n",
       "      <td>0.0110</td>\n",
       "      <td>0.072000</td>\n",
       "      <td>0.55000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hierarchical_random</th>\n",
       "      <td>0.0024</td>\n",
       "      <td>0.057800</td>\n",
       "      <td>0.54260</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pretrained</th>\n",
       "      <td>0.0120</td>\n",
       "      <td>0.072000</td>\n",
       "      <td>0.55180</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>random</th>\n",
       "      <td>0.0052</td>\n",
       "      <td>0.067800</td>\n",
       "      <td>0.54740</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>target</th>\n",
       "      <td>0.0006</td>\n",
       "      <td>0.028200</td>\n",
       "      <td>0.45360</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"6\" valign=\"top\">BiLSTM</th>\n",
       "      <th>baseline</th>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.009000</td>\n",
       "      <td>0.39220</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hierarchical_pretrained</th>\n",
       "      <td>0.0040</td>\n",
       "      <td>0.059600</td>\n",
       "      <td>0.55400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hierarchical_random</th>\n",
       "      <td>0.0038</td>\n",
       "      <td>0.055000</td>\n",
       "      <td>0.53940</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pretrained</th>\n",
       "      <td>0.0094</td>\n",
       "      <td>0.059600</td>\n",
       "      <td>0.55460</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>random</th>\n",
       "      <td>0.0084</td>\n",
       "      <td>0.062200</td>\n",
       "      <td>0.55540</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>target</th>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.024400</td>\n",
       "      <td>0.39560</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"6\" valign=\"top\">CLF</th>\n",
       "      <th>baseline</th>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.003000</td>\n",
       "      <td>0.39825</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hierarchical_pretrained</th>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.054400</td>\n",
       "      <td>0.56920</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hierarchical_random</th>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.005667</td>\n",
       "      <td>0.37300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pretrained</th>\n",
       "      <td>0.0006</td>\n",
       "      <td>0.050000</td>\n",
       "      <td>0.56720</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>random</th>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.037200</td>\n",
       "      <td>0.54120</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>target</th>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.010200</td>\n",
       "      <td>0.42160</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"6\" valign=\"top\">CNN</th>\n",
       "      <th>baseline</th>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.002000</td>\n",
       "      <td>0.39340</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hierarchical_pretrained</th>\n",
       "      <td>0.0062</td>\n",
       "      <td>0.060600</td>\n",
       "      <td>0.47120</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hierarchical_random</th>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.001400</td>\n",
       "      <td>0.33120</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pretrained</th>\n",
       "      <td>0.0024</td>\n",
       "      <td>0.049000</td>\n",
       "      <td>0.50440</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>random</th>\n",
       "      <td>0.0018</td>\n",
       "      <td>0.023400</td>\n",
       "      <td>0.48540</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>target</th>\n",
       "      <td>0.0012</td>\n",
       "      <td>0.018000</td>\n",
       "      <td>0.36440</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "label                               Q2        Q3       Q4\n",
       "Model  att_module                                        \n",
       "BiGRU  baseline                 0.0000  0.012400  0.45120\n",
       "       hierarchical_pretrained  0.0110  0.072000  0.55000\n",
       "       hierarchical_random      0.0024  0.057800  0.54260\n",
       "       pretrained               0.0120  0.072000  0.55180\n",
       "       random                   0.0052  0.067800  0.54740\n",
       "       target                   0.0006  0.028200  0.45360\n",
       "BiLSTM baseline                 0.0000  0.009000  0.39220\n",
       "       hierarchical_pretrained  0.0040  0.059600  0.55400\n",
       "       hierarchical_random      0.0038  0.055000  0.53940\n",
       "       pretrained               0.0094  0.059600  0.55460\n",
       "       random                   0.0084  0.062200  0.55540\n",
       "       target                   0.0000  0.024400  0.39560\n",
       "CLF    baseline                 0.0000  0.003000  0.39825\n",
       "       hierarchical_pretrained  0.0000  0.054400  0.56920\n",
       "       hierarchical_random      0.0000  0.005667  0.37300\n",
       "       pretrained               0.0006  0.050000  0.56720\n",
       "       random                   0.0000  0.037200  0.54120\n",
       "       target                   0.0000  0.010200  0.42160\n",
       "CNN    baseline                 0.0000  0.002000  0.39340\n",
       "       hierarchical_pretrained  0.0062  0.060600  0.47120\n",
       "       hierarchical_random      0.0000  0.001400  0.33120\n",
       "       pretrained               0.0024  0.049000  0.50440\n",
       "       random                   0.0018  0.023400  0.48540\n",
       "       target                   0.0012  0.018000  0.36440"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load results data\n",
    "df_full_q = pd.read_excel(os.path.join(path_results, 'results_section_A', 'MimicFull_scores_quartile_final.xlsx')).drop(['Unnamed: 0'], axis=1)\n",
    "cols_q = ['f1_macro_Q0', 'f1_micro_Q0', 'f1_macro_Q1', 'f1_micro_Q1', 'f1_macro_Q2', 'f1_micro_Q2', 'f1_macro_Q3', 'f1_micro_Q3']\n",
    "df_full_q_grp = df_full_q.groupby(['Model', 'att_module'])[cols_q].mean().reset_index()\n",
    "\n",
    "# Reshape dataframe to have quartile information as column\n",
    "df_full_q_grp = pd.melt(df_full_q_grp, id_vars=['Model', 'att_module'], value_vars=['f1_macro_Q0', 'f1_micro_Q0', \n",
    "                                                                      'f1_macro_Q1', 'f1_micro_Q1',\n",
    "                                                                     'f1_macro_Q2', 'f1_micro_Q2',\n",
    "                                                                     'f1_macro_Q3', 'f1_micro_Q3'])\n",
    "df_full_q_grp[['metric', 'average', 'label']] = df_full_q_grp.variable.str.split('_', expand=True)\n",
    "\n",
    "# Rename quartiles\n",
    "Quartiles = ['Q1', 'Q2', 'Q3']\n",
    "df_full_q_grp = df_full_q_grp[df_full_q_grp['label'].isin(Quartiles)]\n",
    "df_full_q_grp['label'] = df_full_q_grp['label'].map({'Q1': 'Q2',\n",
    "                                                     'Q2': 'Q3',\n",
    "                                                     'Q3': 'Q4'})\n",
    "# Show results for micro scores\n",
    "df_full_q_grp = df_full_q_grp[df_full_q_grp['average']=='micro']\n",
    "df_full_q_grp = df_full_q_grp.groupby(['Model', 'att_module', 'label'])['value'].mean().reset_index()\n",
    "# Reshape dataframe again\n",
    "df_full_q_grp = df_full_q_grp.pivot_table(values='value', index=['Model', 'att_module'], columns='label')\n",
    "df_full_q_grp"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d4f1dba",
   "metadata": {},
   "source": [
    "## Results: MIMIC-III-Full - Individual Label Performances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "852793ea",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of lables: 8907\n",
      "Number of labels kept: 2234/8907\n",
      "Number of labels dropped: 6673/8907\n",
      "Frequency range for Q4: 28-20046; N Labels: 1752/2248\n",
      "Frequency range for Q3: 6-27; N Labels: 452/2312\n",
      "Frequency range for Q2: 2-5; N Labels: 30/2437\n",
      "Frequency range for Q1: 1-1; N Labels: 0/1910\n",
      "Quartile: 2\n",
      "pretrained                 13\n",
      "random                     11\n",
      "hierarchical_pretrained    10\n",
      "hierarchical_random         6\n",
      "target                      2\n",
      "Name: att_module, dtype: int64\n",
      "Quartile: 3\n",
      "hierarchical_pretrained    191\n",
      "pretrained                 143\n",
      "random                     104\n",
      "hierarchical_random         60\n",
      "target                      40\n",
      "baseline                     4\n",
      "Name: att_module, dtype: int64\n",
      "Quartile: 4\n",
      "pretrained                 697\n",
      "hierarchical_pretrained    589\n",
      "random                     307\n",
      "hierarchical_random        152\n",
      "target                      48\n",
      "baseline                    19\n",
      "Name: att_module, dtype: int64\n",
      "CNN\n",
      "pretrained                 710\n",
      "hierarchical_pretrained    600\n",
      "random                     238\n",
      "target                     143\n",
      "baseline                    44\n",
      "hierarchical_random          5\n",
      "Name: att_module, dtype: int64\n",
      "1740\n",
      "\n",
      "BiGRU\n",
      "pretrained                 538\n",
      "hierarchical_pretrained    470\n",
      "random                     443\n",
      "hierarchical_random        358\n",
      "target                      77\n",
      "baseline                    52\n",
      "Name: att_module, dtype: int64\n",
      "1938\n",
      "\n",
      "BiLSTM\n",
      "pretrained                 546\n",
      "random                     524\n",
      "hierarchical_pretrained    515\n",
      "hierarchical_random        252\n",
      "target                      57\n",
      "baseline                    11\n",
      "Name: att_module, dtype: int64\n",
      "1905\n",
      "\n",
      "CLF\n",
      "hierarchical_pretrained    737\n",
      "pretrained                 727\n",
      "random                     244\n",
      "target                      81\n",
      "hierarchical_random         22\n",
      "baseline                    19\n",
      "Name: att_module, dtype: int64\n",
      "1830\n",
      "\n",
      "CNN\n",
      "Quartile: 2\n",
      "hierarchical_pretrained    10\n",
      "pretrained                  2\n",
      "random                      2\n",
      "target                      1\n",
      "Name: att_module, dtype: int64\n",
      "\n",
      "Quartile: 3\n",
      "hierarchical_pretrained    166\n",
      "pretrained                  79\n",
      "target                      23\n",
      "random                      19\n",
      "baseline                     1\n",
      "Name: att_module, dtype: int64\n",
      "\n",
      "Quartile: 4\n",
      "pretrained                 629\n",
      "hierarchical_pretrained    424\n",
      "random                     217\n",
      "target                     119\n",
      "baseline                    43\n",
      "hierarchical_random          5\n",
      "Name: att_module, dtype: int64\n",
      "\n",
      "BiGRU\n",
      "Quartile: 2\n",
      "pretrained                 8\n",
      "hierarchical_pretrained    5\n",
      "random                     5\n",
      "hierarchical_random        4\n",
      "target                     1\n",
      "Name: att_module, dtype: int64\n",
      "\n",
      "Quartile: 3\n",
      "hierarchical_pretrained    89\n",
      "pretrained                 79\n",
      "random                     74\n",
      "hierarchical_random        65\n",
      "target                     23\n",
      "baseline                    3\n",
      "Name: att_module, dtype: int64\n",
      "\n",
      "Quartile: 4\n",
      "pretrained                 451\n",
      "hierarchical_pretrained    376\n",
      "random                     364\n",
      "hierarchical_random        289\n",
      "target                      53\n",
      "baseline                    49\n",
      "Name: att_module, dtype: int64\n",
      "\n",
      "BiLSTM\n",
      "Quartile: 2\n",
      "random                 7\n",
      "pretrained             6\n",
      "hierarchical_random    2\n",
      "Name: att_module, dtype: int64\n",
      "\n",
      "Quartile: 3\n",
      "hierarchical_pretrained    86\n",
      "random                     84\n",
      "pretrained                 81\n",
      "hierarchical_random        52\n",
      "target                     13\n",
      "baseline                    2\n",
      "Name: att_module, dtype: int64\n",
      "\n",
      "Quartile: 4\n",
      "pretrained                 459\n",
      "random                     433\n",
      "hierarchical_pretrained    429\n",
      "hierarchical_random        198\n",
      "target                      44\n",
      "baseline                     9\n",
      "Name: att_module, dtype: int64\n",
      "\n",
      "CLF\n",
      "Quartile: 2\n",
      "pretrained    1\n",
      "Name: att_module, dtype: int64\n",
      "\n",
      "Quartile: 3\n",
      "hierarchical_pretrained    98\n",
      "pretrained                 85\n",
      "random                     55\n",
      "target                      7\n",
      "hierarchical_random         5\n",
      "Name: att_module, dtype: int64\n",
      "\n",
      "Quartile: 4\n",
      "pretrained                 641\n",
      "hierarchical_pretrained    639\n",
      "random                     189\n",
      "target                      74\n",
      "baseline                    19\n",
      "hierarchical_random         17\n",
      "Name: att_module, dtype: int64\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Individual label performance\n",
    "\n",
    "# Load dataframe with individual label performance\n",
    "# Since the label space is very large, the majority of labels achieve a performance of 0 across all models\n",
    "# To save memory we are removing and keeping track of these labels\n",
    "\n",
    "# Load results chunkwise to be memory efficient\n",
    "file_path = os.path.join(path_results, 'results_section_A', 'MimicFull_scores_individual_final.csv')\n",
    "\n",
    "model_parameters = []\n",
    "labels_kept = []\n",
    "\n",
    "\n",
    "for c, chunk in enumerate(pd.read_csv(file_path, chunksize=5)):\n",
    "    # Remove unwanted column\n",
    "    chunk = chunk.drop(['Unnamed: 0'], axis=1)\n",
    "    \n",
    "    # Get model indicate varibales for current chunk and append those to list\n",
    "    # We match these later to the dataset\n",
    "    chunk_models = chunk.iloc[:, :15]\n",
    "    model_parameters.append(chunk_models)\n",
    "    \n",
    "    # Get part of dataframe with only performance results\n",
    "    chunk = chunk.iloc[:,15:]\n",
    "    \n",
    "    # Retain only columns / labels that have a performance other than 0 for any of the models in the chunk\n",
    "    chunk_sub = chunk.loc[:, (chunk != 0).any(axis=0)]\n",
    "    \n",
    "    # Only add columns/labels to list that arent already in the list\n",
    "    for label in chunk_sub.columns:\n",
    "        if label not in labels_kept:\n",
    "            labels_kept.append(label)\n",
    "            \n",
    "labels_dropped = []\n",
    "\n",
    "for label in chunk.columns:\n",
    "    if label not in labels_kept:\n",
    "        labels_dropped.append(label)\n",
    "        \n",
    "        \n",
    "        \n",
    "# Load the dataset again and filter\n",
    "\n",
    "chunks = []\n",
    "\n",
    "for c, chunk in enumerate(pd.read_csv(file_path, chunksize=5)):\n",
    "    chunk = chunk.drop('Unnamed: 0', axis=1)\n",
    "    if c == 0:\n",
    "        models = chunk.columns[:15].tolist()\n",
    "    chunks.append(chunk[models+labels_kept])\n",
    "    \n",
    "\n",
    "print(f'Total number of lables: {len(labels_kept) + len(labels_dropped)}')\n",
    "print(f'Number of labels kept: {len(labels_kept)}/{len(labels_kept) + len(labels_dropped)}')\n",
    "print(f'Number of labels dropped: {len(labels_dropped)}/{len(labels_kept) + len(labels_dropped)}')\n",
    "\n",
    "labels_kept = [col.split('_')[-1] for col in labels_kept]\n",
    "labels_dropped = [col.split('_')[-1] for col in labels_dropped]\n",
    "\n",
    "with open(os.path.join(root, 'data', 'processed', 'data_MimicFull', 'l_codes_MimicFull.pkl'), 'rb') as f:\n",
    "    mimicFull_labels = pickle.load(f)\n",
    "\n",
    "mimicFull_labelindices = [mimicFull_labels.index(label) for label in labels_kept]\n",
    "\n",
    "with open(os.path.join(path_results, 'results_section_A', 'labels_kept.pkl'), 'wb') as f:\n",
    "    pickle.dump(labels_kept, f)\n",
    "\n",
    "with open(os.path.join(path_results, 'results_section_A', 'labels_kept_index.pkl'), 'wb') as f:\n",
    "    pickle.dump(mimicFull_labelindices, f)\n",
    "    \n",
    "with open(os.path.join(path_results, 'results_section_A', 'labels_dropped.pkl'), 'wb') as f:\n",
    "    pickle.dump(labels_dropped, f)    \n",
    "\n",
    "dff_i_reduced = pd.concat(chunks)\n",
    "dff_i_reduced\n",
    "\n",
    "cols_new = []\n",
    "for c, col in enumerate(dff_i_reduced.columns):\n",
    "    if c > 14:\n",
    "        col = col.split('_')[-1]\n",
    "    cols_new.append(col)\n",
    "        \n",
    "dff_i_reduced.columns = cols_new \n",
    "        \n",
    "dff_i_reduced.to_csv(os.path.join(path_results, 'results_section_A', 'mimicfull_scores_individual_final_reduced.csv'))\n",
    "dff_i_reduced.to_excel(os.path.join(path_results, 'results_section_A', 'mimicfull_scores_individual_final_reduced.xlsx'))\n",
    "\n",
    "## Analysis: Performance breakdown of attention types\n",
    "\n",
    "#RQ1: Which type of attention consistently achieves the best-performance per label?\n",
    "\n",
    "#    - Across all text encoder architectures combined\n",
    "#    - For each text encoder architecture\n",
    "#    - Across the label frequency quartiles\n",
    "\n",
    "# Model load reduced dataset\n",
    "\n",
    "dff_i_reduced = pd.read_csv(os.path.join(path_results, 'results_section_A', 'MimicFull_scores_individual_final_reduced.csv')).drop('Unnamed: 0', axis=1)\n",
    "\n",
    "# Load dictionary describing each label\n",
    "with open(os.path.join(root, 'data', 'processed', 'data_MimicFull', 'l_codes_dict_MimicFull.pkl'), 'rb') as f:\n",
    "    mimicfull_quartiles = pickle.load(f)\n",
    "    \n",
    "with open(os.path.join(path_results, 'results_section_A', 'labels_kept.pkl'), 'rb') as f:\n",
    "    labels_kept = pickle.load(f)\n",
    "\n",
    "mimicfull_quartiles\n",
    "\n",
    "d = {}\n",
    "d_counts_kept = {}\n",
    "for key, item in mimicfull_quartiles.items():\n",
    "    quartile = item['quartile']\n",
    "    freq = item['freq']\n",
    "    if quartile not in d.keys():\n",
    "        d[quartile] = []\n",
    "    d[quartile].append(freq)\n",
    "    \n",
    "    \n",
    "    if key in labels_kept:\n",
    "        if quartile not in d_counts_kept.keys():\n",
    "            d_counts_kept[quartile] = 1\n",
    "        else:\n",
    "            d_counts_kept[quartile] += 1\n",
    "    \n",
    "\n",
    "for q, freqs in d.items():\n",
    "    max_freq = max(freqs)\n",
    "    min_freq = min(freqs)\n",
    "    \n",
    "    if q != 0:\n",
    "        kept_labels = d_counts_kept[q]\n",
    "    else:\n",
    "        kept_labels = 0 \n",
    "    \n",
    "    print(f'Frequency range for Q{q+1}: {min_freq}-{max_freq}; N Labels: {kept_labels}/{len(freqs)}')\n",
    "    \n",
    "    \n",
    "d_above_100 = [freq for freq in d[3] if freq > 100]\n",
    "dff_i_grp = dff_i_reduced.groupby(['Model', 'att_module'])[labels_kept].mean().reset_index()\n",
    "\n",
    "dff_i_grp_melt = pd.melt(dff_i_grp, id_vars=['Model', 'att_module'], value_vars=labels_kept,\n",
    "                         var_name='label', value_name='mean')\n",
    "\n",
    "dff_i_grp_melt['quartile'] = dff_i_grp_melt.apply(lambda x: mimicfull_quartiles[x.label]['quartile'], axis=1)\n",
    "dff_i_grp_melt\n",
    "\n",
    "len(mimicfull_quartiles)\n",
    "\n",
    "## Across all models\n",
    "\n",
    "dff_i_nonzeros = dff_i_grp_melt[dff_i_grp_melt['mean']!=0]\n",
    "idx = dff_i_nonzeros.groupby(['label'])['mean'].transform(max) == dff_i_nonzeros['mean']\n",
    "dff_i_max = dff_i_nonzeros[idx].reset_index(drop=True)\n",
    "\n",
    "dff_i_max['att_module'].value_counts()\n",
    "\n",
    "\n",
    "# Split by quartiles\n",
    "\n",
    "quartiles = [1, 2, 3]\n",
    "\n",
    "for q in quartiles:\n",
    "    print(f'Quartile: {q+1}')\n",
    "    df_q = dff_i_grp_melt[dff_i_grp_melt['quartile']==q]\n",
    "    df_q = df_q[df_q['mean'] != 0]\n",
    "    idx = df_q.groupby(['label'])['mean'].transform(max) == df_q['mean']\n",
    "    dff_i_max = df_q[idx].reset_index(drop=True)\n",
    "    print(dff_i_max['att_module'].value_counts())\n",
    "\n",
    "# Across each text encoder architecture\n",
    "\n",
    "models = ['CNN', 'BiGRU', 'BiLSTM', 'CLF']\n",
    "\n",
    "for model in models:\n",
    "    print(model)\n",
    "    df_model = dff_i_grp_melt[dff_i_grp_melt['Model']==model]\n",
    "\n",
    "    df_model = df_model[df_model['mean'] != 0]\n",
    "            \n",
    "    idx = df_model.groupby(['label'])['mean'].transform(max) == df_model['mean']\n",
    "    dff_i_max = df_model[idx].reset_index(drop=True)\n",
    "\n",
    "    print(dff_i_max['att_module'].value_counts())\n",
    "    print(sum(dff_i_max['att_module'].value_counts()))\n",
    "\n",
    "    \n",
    "    print()\n",
    "\n",
    "\n",
    "\n",
    "models = ['CNN', 'BiGRU', 'BiLSTM', 'CLF']\n",
    "\n",
    "for model in models:\n",
    "    print(model)\n",
    "    df_model = dff_i_grp_melt[dff_i_grp_melt['Model']==model]\n",
    "    \n",
    "    for q in quartiles:\n",
    "        print(f'Quartile: {q+1}')\n",
    "        df_q = df_model[df_model['quartile']==q]\n",
    "                \n",
    "        df_q = df_q[df_q['mean'] != 0]\n",
    "            \n",
    "        idx = df_q.groupby(['label'])['mean'].transform(max) == df_q['mean']\n",
    "        dff_i_max = df_q[idx].reset_index(drop=True)\n",
    "    \n",
    "        print(dff_i_max['att_module'].value_counts())\n",
    "        print()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ad38705",
   "metadata": {},
   "source": [
    "# Results - Section B: MIMIC-III-50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "dfb1eea9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>att_module</th>\n",
       "      <th>f1_macro_sk_mean</th>\n",
       "      <th>f1_macro_sk_ci_95</th>\n",
       "      <th>f1_micro_sk_mean</th>\n",
       "      <th>f1_micro_sk_ci_95</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>BiGRU</td>\n",
       "      <td>baseline</td>\n",
       "      <td>0.46468</td>\n",
       "      <td>0.012070</td>\n",
       "      <td>0.58596</td>\n",
       "      <td>0.007683</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>BiGRU</td>\n",
       "      <td>hierarchical_pretrained</td>\n",
       "      <td>0.55584</td>\n",
       "      <td>0.005706</td>\n",
       "      <td>0.65468</td>\n",
       "      <td>0.003152</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>BiGRU</td>\n",
       "      <td>hierarchical_random</td>\n",
       "      <td>0.50104</td>\n",
       "      <td>0.005591</td>\n",
       "      <td>0.61332</td>\n",
       "      <td>0.004901</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>BiGRU</td>\n",
       "      <td>pretrained</td>\n",
       "      <td>0.53352</td>\n",
       "      <td>0.004137</td>\n",
       "      <td>0.64292</td>\n",
       "      <td>0.002637</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>BiGRU</td>\n",
       "      <td>random</td>\n",
       "      <td>0.49596</td>\n",
       "      <td>0.006481</td>\n",
       "      <td>0.62196</td>\n",
       "      <td>0.003566</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>BiGRU</td>\n",
       "      <td>target</td>\n",
       "      <td>0.42640</td>\n",
       "      <td>0.009445</td>\n",
       "      <td>0.55160</td>\n",
       "      <td>0.006508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>BiLSTM</td>\n",
       "      <td>baseline</td>\n",
       "      <td>0.34280</td>\n",
       "      <td>0.008073</td>\n",
       "      <td>0.47936</td>\n",
       "      <td>0.006595</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>BiLSTM</td>\n",
       "      <td>hierarchical_pretrained</td>\n",
       "      <td>0.52096</td>\n",
       "      <td>0.003367</td>\n",
       "      <td>0.63348</td>\n",
       "      <td>0.002756</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>BiLSTM</td>\n",
       "      <td>hierarchical_random</td>\n",
       "      <td>0.46468</td>\n",
       "      <td>0.010127</td>\n",
       "      <td>0.58648</td>\n",
       "      <td>0.008289</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>BiLSTM</td>\n",
       "      <td>pretrained</td>\n",
       "      <td>0.51572</td>\n",
       "      <td>0.005827</td>\n",
       "      <td>0.63328</td>\n",
       "      <td>0.004117</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>BiLSTM</td>\n",
       "      <td>random</td>\n",
       "      <td>0.47004</td>\n",
       "      <td>0.007898</td>\n",
       "      <td>0.59424</td>\n",
       "      <td>0.005815</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>BiLSTM</td>\n",
       "      <td>target</td>\n",
       "      <td>0.41652</td>\n",
       "      <td>0.011218</td>\n",
       "      <td>0.54008</td>\n",
       "      <td>0.008326</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>CLF</td>\n",
       "      <td>baseline</td>\n",
       "      <td>0.40380</td>\n",
       "      <td>0.010299</td>\n",
       "      <td>0.54008</td>\n",
       "      <td>0.007426</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>CLF</td>\n",
       "      <td>hierarchical_pretrained</td>\n",
       "      <td>0.57384</td>\n",
       "      <td>0.006401</td>\n",
       "      <td>0.66180</td>\n",
       "      <td>0.004189</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>CLF</td>\n",
       "      <td>hierarchical_random</td>\n",
       "      <td>0.53792</td>\n",
       "      <td>0.008505</td>\n",
       "      <td>0.63560</td>\n",
       "      <td>0.003990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>CLF</td>\n",
       "      <td>pretrained</td>\n",
       "      <td>0.57020</td>\n",
       "      <td>0.007522</td>\n",
       "      <td>0.65944</td>\n",
       "      <td>0.004501</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>CLF</td>\n",
       "      <td>random</td>\n",
       "      <td>0.55316</td>\n",
       "      <td>0.007017</td>\n",
       "      <td>0.64540</td>\n",
       "      <td>0.003107</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>CLF</td>\n",
       "      <td>target</td>\n",
       "      <td>0.54292</td>\n",
       "      <td>0.006128</td>\n",
       "      <td>0.63924</td>\n",
       "      <td>0.004320</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>CNN</td>\n",
       "      <td>baseline</td>\n",
       "      <td>0.42696</td>\n",
       "      <td>0.008278</td>\n",
       "      <td>0.55772</td>\n",
       "      <td>0.007796</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>CNN</td>\n",
       "      <td>hierarchical_pretrained</td>\n",
       "      <td>0.51388</td>\n",
       "      <td>0.004810</td>\n",
       "      <td>0.62468</td>\n",
       "      <td>0.002331</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>CNN</td>\n",
       "      <td>hierarchical_random</td>\n",
       "      <td>0.44952</td>\n",
       "      <td>0.009292</td>\n",
       "      <td>0.57180</td>\n",
       "      <td>0.007384</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>CNN</td>\n",
       "      <td>pretrained</td>\n",
       "      <td>0.51476</td>\n",
       "      <td>0.005023</td>\n",
       "      <td>0.62292</td>\n",
       "      <td>0.003098</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>CNN</td>\n",
       "      <td>random</td>\n",
       "      <td>0.54236</td>\n",
       "      <td>0.003641</td>\n",
       "      <td>0.64008</td>\n",
       "      <td>0.002067</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>CNN</td>\n",
       "      <td>target</td>\n",
       "      <td>0.42364</td>\n",
       "      <td>0.006034</td>\n",
       "      <td>0.53884</td>\n",
       "      <td>0.003524</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     model               att_module  f1_macro_sk_mean  f1_macro_sk_ci_95  \\\n",
       "0    BiGRU                 baseline           0.46468           0.012070   \n",
       "1    BiGRU  hierarchical_pretrained           0.55584           0.005706   \n",
       "2    BiGRU      hierarchical_random           0.50104           0.005591   \n",
       "3    BiGRU               pretrained           0.53352           0.004137   \n",
       "4    BiGRU                   random           0.49596           0.006481   \n",
       "5    BiGRU                   target           0.42640           0.009445   \n",
       "6   BiLSTM                 baseline           0.34280           0.008073   \n",
       "7   BiLSTM  hierarchical_pretrained           0.52096           0.003367   \n",
       "8   BiLSTM      hierarchical_random           0.46468           0.010127   \n",
       "9   BiLSTM               pretrained           0.51572           0.005827   \n",
       "10  BiLSTM                   random           0.47004           0.007898   \n",
       "11  BiLSTM                   target           0.41652           0.011218   \n",
       "12     CLF                 baseline           0.40380           0.010299   \n",
       "13     CLF  hierarchical_pretrained           0.57384           0.006401   \n",
       "14     CLF      hierarchical_random           0.53792           0.008505   \n",
       "15     CLF               pretrained           0.57020           0.007522   \n",
       "16     CLF                   random           0.55316           0.007017   \n",
       "17     CLF                   target           0.54292           0.006128   \n",
       "18     CNN                 baseline           0.42696           0.008278   \n",
       "19     CNN  hierarchical_pretrained           0.51388           0.004810   \n",
       "20     CNN      hierarchical_random           0.44952           0.009292   \n",
       "21     CNN               pretrained           0.51476           0.005023   \n",
       "22     CNN                   random           0.54236           0.003641   \n",
       "23     CNN                   target           0.42364           0.006034   \n",
       "\n",
       "    f1_micro_sk_mean  f1_micro_sk_ci_95  \n",
       "0            0.58596           0.007683  \n",
       "1            0.65468           0.003152  \n",
       "2            0.61332           0.004901  \n",
       "3            0.64292           0.002637  \n",
       "4            0.62196           0.003566  \n",
       "5            0.55160           0.006508  \n",
       "6            0.47936           0.006595  \n",
       "7            0.63348           0.002756  \n",
       "8            0.58648           0.008289  \n",
       "9            0.63328           0.004117  \n",
       "10           0.59424           0.005815  \n",
       "11           0.54008           0.008326  \n",
       "12           0.54008           0.007426  \n",
       "13           0.66180           0.004189  \n",
       "14           0.63560           0.003990  \n",
       "15           0.65944           0.004501  \n",
       "16           0.64540           0.003107  \n",
       "17           0.63924           0.004320  \n",
       "18           0.55772           0.007796  \n",
       "19           0.62468           0.002331  \n",
       "20           0.57180           0.007384  \n",
       "21           0.62292           0.003098  \n",
       "22           0.64008           0.002067  \n",
       "23           0.53884           0.003524  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_50 = pd.read_excel(os.path.join(path_results, 'results_section_B', 'Mimic50_scores.xlsx')).drop(['Unnamed: 0'], axis=1)\n",
    "# Group data based on model and attention or baseline method\n",
    "df_50_grp = df_50.groupby(['Model', 'att_module'])[['f1_macro_sk', 'f1_micro_sk']].agg(['mean', ci_95]).reset_index()\n",
    "# Remove multi-level column indexing and corrent column naming\n",
    "df_50_grp.columns = df_50_grp.columns.map('{0[0]}_{0[1]}'.format)\n",
    "df_50_grp = df_50_grp.rename(columns={\"Model_\": \"model\", \"att_module_\": \"att_module\"})\n",
    "df_50_grp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "620f45cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_pos_micros: [-6.8, -4.2, -1.8, 0.8, 3.2, 5.8]\n",
      "x_pos_macros: [-5.8, -3.2, -0.8, 1.8, 4.2, 6.8]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x576 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "width = 1\n",
    "\n",
    "\n",
    "# Visualize scores\n",
    "fig, ax = plt.subplots(figsize=(10, 8), facecolor='white')\n",
    "\n",
    "# Scale X-positions - impacts proximity between the bars of different text-encoder architectures\n",
    "X = np.arange(len(models)) * 18\n",
    "x_pos_micros, x_pos_macros = get_xdeltas_barplot(width=width, gap_width=1.5, n_bars=6)\n",
    "\n",
    "# Color scale\n",
    "colors = sns.color_palette('colorblind').as_hex()[:len(atts)]\n",
    "\n",
    "# We are plotting the micro and macro F1-scores right next to each other\n",
    "for average in averages:\n",
    "    # F1-score averages have different offset values\n",
    "    if average == 'micro':\n",
    "        x_deltas = x_pos_micros\n",
    "    elif average == 'macro':\n",
    "        x_deltas = x_pos_macros\n",
    "    \n",
    "    # Loop through considered text-encoder architectures (i.e., models)\n",
    "    # Each model has its own primary x-coordinate\n",
    "    for x, model in zip(X, models):\n",
    "        df_model = df_50_grp[df_50_grp['model']==model]\n",
    "        \n",
    "        # Loop through baseline and attention mechanisms list\n",
    "        # Each method has its own offset\n",
    "        # Each method has its own color\n",
    "        for c, (x_delta, att) in enumerate(zip(x_deltas, atts)):\n",
    "            # Get values from dataframe\n",
    "            height = df_model[df_model['att_module']==att][f'f1_{average}_sk_mean']\n",
    "            err = df_model[df_model['att_module']==att][f'f1_{average}_sk_ci_95']\n",
    "\n",
    "            # Plot results\n",
    "            if average == 'macro':\n",
    "                plt.bar(x = x + x_delta, height=height, yerr=err,\n",
    "                        color=colors[c], edgecolor='k',\n",
    "                        width=width, hatch='\\\\\\\\\\\\\\\\', align='edge', zorder=3,\n",
    "                        error_kw=dict(lw=2, capsize=3, capthick=1.5, ecolor='k'))\n",
    "            else:\n",
    "                plt.bar(x = x + x_delta, height=height, yerr=err,\n",
    "                        color=colors[c], edgecolor='k',\n",
    "                        width=width, align='edge', zorder=3,\n",
    "                        error_kw=dict(lw=2, capsize=3, capthick=1.5, ecolor='k'))\n",
    "                \n",
    "ax.set_xticks(X+0.25)\n",
    "xlabels = ['CNN', 'Bi-GRU', 'Bi-LSTM', 'CLF']\n",
    "ax.set_xticklabels(xlabels, fontsize=24)\n",
    "\n",
    "ax.set_yticks(np.arange(0, 0.8, 0.1))\n",
    "ax.set_yticklabels([0, 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7], fontsize=16)\n",
    "\n",
    "#plt.xlabel('Text Encoder Architecture', fontsize=18)\n",
    "plt.xlabel('')\n",
    "plt.ylabel('F1-Score', fontsize=24)\n",
    "\n",
    "ax.spines.right.set_visible(False)\n",
    "ax.spines.left.set_visible(False)\n",
    "ax.spines.top.set_visible(False)\n",
    "\n",
    "fig.tight_layout()\n",
    "plt.grid( which='major', axis='y', zorder=0)\n",
    "plt.tick_params(left = False)\n",
    "\n",
    "\n",
    "\n",
    "# generate legend\n",
    "xlabels = ['Architecture-Specific Baseline', 'Target-Attention', \n",
    "                    'Random Label-Attention', 'Pretrained Label-Attention',\n",
    "                    'Hierarchical Random Label-Attention', 'Hierarchical Pretrained Label-Attention']\n",
    "legend_elements = []\n",
    "\n",
    "for color, label in zip(colors, xlabels):\n",
    "    patch = Patch(facecolor=color, label=label, edgecolor='k')\n",
    "    legend_elements.append(patch)\n",
    "\n",
    "legend_elements.append(Patch(label='Macro-Average', hatch='\\\\\\\\\\\\\\\\', edgecolor='k', facecolor='none', linewidth=1))\n",
    "legend_elements.append(Patch(label='Micro-Average', hatch=None, edgecolor='k', facecolor='none', linewidth=1))\n",
    "\n",
    "#plt.suptitle('Experimental Results for MIMIC-III-50', \n",
    "    #         fontsize=22, fontweight='bold', y=1.05, fontname='Helvetica')\n",
    "\n",
    "\n",
    "\n",
    "plt.legend(loc='lower center', fontsize=16, ncol=2, frameon=False, bbox_to_anchor=(0.5,-0.28),\n",
    "          handles=legend_elements)\n",
    "ax.set_facecolor('w')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b27cf7c6",
   "metadata": {},
   "source": [
    "# Count Best-Performance Across Quartiles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4036b126",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(os.path.join(root, 'data', 'processed', 'data_Mimic50', 'l_codes_dict_Mimic50.pkl'), 'rb') as f:\n",
    "    mimic50_quartiles = pickle.load(f)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d9d823bf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "hierarchical_pretrained    30\n",
       "pretrained                 11\n",
       "random                      9\n",
       "Name: att_module, dtype: int64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "######################\n",
    "# Load results for label attention mechanisms\n",
    "df_50_i = pd.read_excel(os.path.join(path_results, 'results_section_B', 'Mimic50_scores_individual.xlsx')).drop('Unnamed: 0', axis=1)\n",
    "df_50_i = df_50_i.drop(['dataset', 'doc_max_len', 'batch_size', 'patience', 'embedding_scaling',\n",
    "                      'word_embedding_dim', 'kernel_sizes', 'hidden_dim', 'dropout_p', 'scale',\n",
    "                      'multihead', 'num_heads'], axis=1)\n",
    "df_50_i_melt = pd.melt(df_50_i, id_vars=['Model', 'att_module', 'seed']).sort_values(['Model', 'seed', 'att_module', 'variable'])\n",
    "df_50_i_melt[['metric', 'average', 'label']] = df_50_i_melt.variable.str.split('_', expand=True)\n",
    "df_50_i_melt = df_50_i_melt.drop(['variable', 'metric', 'average'], axis=1)\n",
    "\n",
    "df_50_i_melt['freq'] = df_50_i_melt.apply(lambda x: mimic50_quartiles[x.label]['freq'], axis=1)\n",
    "df_50_i_melt['quartile'] = df_50_i_melt.apply(lambda x: mimic50_quartiles[x.label]['quartile'], axis=1)\n",
    "#df_50_i_melt['desc'] = df_50_i_melt.apply(lambda x: mimic50_desc[x.label], axis=1)\n",
    "df_50_i = df_50_i_melt.groupby(['Model', 'label', 'att_module', 'quartile', 'freq'])['value'].agg(['mean', 'std']).reset_index().sort_values(['Model'])\n",
    "df_50_i = df_50_i.sort_values(['Model', 'label', 'att_module'])\n",
    "\n",
    "idx = df_50_i.groupby(['label'])['mean'].transform(max) == df_50_i['mean']\n",
    "\n",
    "df_50_i_max = df_50_i[idx].reset_index(drop=True)\n",
    "\n",
    "df_50_i_max['att_module'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "439fd25f",
   "metadata": {},
   "source": [
    "### Best Performance per Quartile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2424c641",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Quartile: 1\n",
      "hierarchical_pretrained    8\n",
      "random                     3\n",
      "pretrained                 2\n",
      "Name: att_module, dtype: int64\n",
      "\n",
      "Quartile: 2\n",
      "hierarchical_pretrained    8\n",
      "pretrained                 4\n",
      "Name: att_module, dtype: int64\n",
      "\n",
      "Quartile: 3\n",
      "hierarchical_pretrained    8\n",
      "random                     3\n",
      "pretrained                 1\n",
      "Name: att_module, dtype: int64\n",
      "\n",
      "Quartile: 4\n",
      "hierarchical_pretrained    6\n",
      "pretrained                 4\n",
      "random                     3\n",
      "Name: att_module, dtype: int64\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for q in [0, 1, 2, 3]:\n",
    "    print(f'Quartile: {q+1}')\n",
    "    dfq = df_50_i[df_50_i['quartile']==q]\n",
    "    idx = dfq.groupby(['label'])['mean'].transform(max) == dfq['mean']\n",
    "\n",
    "    dfq_max = dfq[idx].reset_index(drop=True)\n",
    "    print(dfq_max['att_module'].value_counts())\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f07ddee",
   "metadata": {},
   "source": [
    "### Frequency Count of Labels achieving their best performance with a specific type of attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "382ca8b2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model: CNN\n",
      "random                     33\n",
      "hierarchical_pretrained    12\n",
      "pretrained                  7\n",
      "hierarchical_random         1\n",
      "Name: att_module, dtype: int64\n",
      "\n",
      "model: BiGRU\n",
      "hierarchical_pretrained    30\n",
      "pretrained                 12\n",
      "random                      8\n",
      "hierarchical_random         6\n",
      "Name: att_module, dtype: int64\n",
      "\n",
      "model: BiLSTM\n",
      "hierarchical_pretrained    21\n",
      "pretrained                 19\n",
      "random                      9\n",
      "hierarchical_random         1\n",
      "Name: att_module, dtype: int64\n",
      "\n",
      "model: CLF\n",
      "hierarchical_pretrained    27\n",
      "pretrained                 13\n",
      "random                     10\n",
      "Name: att_module, dtype: int64\n",
      "\n"
     ]
    }
   ],
   "source": [
    "models = ['CNN', 'BiGRU', 'BiLSTM', 'CLF']\n",
    "for model in models:\n",
    "    print(f'model: {model}')\n",
    "    dfm = df_50_i[df_50_i['Model']==model]\n",
    "    idx = dfm.groupby(['label'])['mean'].transform(max) == dfm['mean']\n",
    "\n",
    "    dfm_max = dfm[idx].reset_index(drop=True)\n",
    "    print(dfm_max['att_module'].value_counts())\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "980ac667",
   "metadata": {},
   "source": [
    "### Frequency Count of Labels achieving their best performance with a specific type of attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e8606018",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model: CNN\n",
      "Quartile: 1\n",
      "random                     10\n",
      "pretrained                  3\n",
      "hierarchical_pretrained     2\n",
      "hierarchical_random         1\n",
      "Name: att_module, dtype: int64\n",
      "\n",
      "Quartile: 2\n",
      "random                     8\n",
      "hierarchical_pretrained    3\n",
      "pretrained                 1\n",
      "Name: att_module, dtype: int64\n",
      "\n",
      "Quartile: 3\n",
      "random                     8\n",
      "pretrained                 2\n",
      "hierarchical_pretrained    2\n",
      "Name: att_module, dtype: int64\n",
      "\n",
      "Quartile: 4\n",
      "random                     7\n",
      "hierarchical_pretrained    5\n",
      "pretrained                 1\n",
      "Name: att_module, dtype: int64\n",
      "\n",
      "model: BiGRU\n",
      "Quartile: 1\n",
      "hierarchical_pretrained    9\n",
      "hierarchical_random        4\n",
      "pretrained                 3\n",
      "random                     3\n",
      "Name: att_module, dtype: int64\n",
      "\n",
      "Quartile: 2\n",
      "hierarchical_pretrained    8\n",
      "pretrained                 3\n",
      "hierarchical_random        1\n",
      "Name: att_module, dtype: int64\n",
      "\n",
      "Quartile: 3\n",
      "hierarchical_pretrained    8\n",
      "random                     3\n",
      "pretrained                 1\n",
      "Name: att_module, dtype: int64\n",
      "\n",
      "Quartile: 4\n",
      "hierarchical_pretrained    5\n",
      "pretrained                 5\n",
      "random                     2\n",
      "hierarchical_random        1\n",
      "Name: att_module, dtype: int64\n",
      "\n",
      "model: BiLSTM\n",
      "Quartile: 1\n",
      "hierarchical_pretrained    6\n",
      "pretrained                 4\n",
      "random                     2\n",
      "hierarchical_random        1\n",
      "Name: att_module, dtype: int64\n",
      "\n",
      "Quartile: 2\n",
      "pretrained                 7\n",
      "hierarchical_pretrained    3\n",
      "random                     2\n",
      "Name: att_module, dtype: int64\n",
      "\n",
      "Quartile: 3\n",
      "hierarchical_pretrained    7\n",
      "random                     5\n",
      "Name: att_module, dtype: int64\n",
      "\n",
      "Quartile: 4\n",
      "pretrained                 8\n",
      "hierarchical_pretrained    5\n",
      "Name: att_module, dtype: int64\n",
      "\n",
      "model: CLF\n",
      "Quartile: 1\n",
      "hierarchical_pretrained    9\n",
      "random                     3\n",
      "pretrained                 1\n",
      "Name: att_module, dtype: int64\n",
      "\n",
      "Quartile: 2\n",
      "hierarchical_pretrained    8\n",
      "pretrained                 3\n",
      "random                     1\n",
      "Name: att_module, dtype: int64\n",
      "\n",
      "Quartile: 3\n",
      "random                     5\n",
      "hierarchical_pretrained    4\n",
      "pretrained                 3\n",
      "Name: att_module, dtype: int64\n",
      "\n",
      "Quartile: 4\n",
      "pretrained                 6\n",
      "hierarchical_pretrained    6\n",
      "random                     1\n",
      "Name: att_module, dtype: int64\n",
      "\n"
     ]
    }
   ],
   "source": [
    "models = ['CNN', 'BiGRU', 'BiLSTM', 'CLF']\n",
    "for model in models:\n",
    "    print(f'model: {model}')\n",
    "    dfm = df_50_i[df_50_i['Model']==model]\n",
    "    for q in [0, 1, 2, 3]:\n",
    "        print(f'Quartile: {q+1}')\n",
    "        dfq = dfm[dfm['quartile']==q]\n",
    "        idx = dfq.groupby(['label'])['mean'].transform(max) == dfq['mean']\n",
    "\n",
    "        dfq_max = dfq[idx].reset_index(drop=True)\n",
    "        print(dfq_max['att_module'].value_counts())\n",
    "        print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "615ea9d3",
   "metadata": {},
   "source": [
    "# Results Section C: MIMIC-III-Full - Multihead"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "cbce2dea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>att_module</th>\n",
       "      <th>num_heads</th>\n",
       "      <th>f1_macro_sk_mean</th>\n",
       "      <th>f1_macro_sk_ci_95</th>\n",
       "      <th>f1_micro_sk_mean</th>\n",
       "      <th>f1_micro_sk_ci_95</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>BiGRU</td>\n",
       "      <td>hierarchical_pretrained</td>\n",
       "      <td>2</td>\n",
       "      <td>0.078000</td>\n",
       "      <td>0.007234</td>\n",
       "      <td>0.52025</td>\n",
       "      <td>0.013210</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>BiGRU</td>\n",
       "      <td>hierarchical_pretrained</td>\n",
       "      <td>4</td>\n",
       "      <td>0.072500</td>\n",
       "      <td>0.000919</td>\n",
       "      <td>0.52025</td>\n",
       "      <td>0.003528</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>BiGRU</td>\n",
       "      <td>hierarchical_pretrained</td>\n",
       "      <td>8</td>\n",
       "      <td>0.067000</td>\n",
       "      <td>0.038119</td>\n",
       "      <td>0.52150</td>\n",
       "      <td>0.031766</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>BiGRU</td>\n",
       "      <td>hierarchical_random</td>\n",
       "      <td>2</td>\n",
       "      <td>0.074000</td>\n",
       "      <td>0.027222</td>\n",
       "      <td>0.51475</td>\n",
       "      <td>0.030146</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>BiGRU</td>\n",
       "      <td>hierarchical_random</td>\n",
       "      <td>4</td>\n",
       "      <td>0.075250</td>\n",
       "      <td>0.015503</td>\n",
       "      <td>0.51750</td>\n",
       "      <td>0.022068</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>BiGRU</td>\n",
       "      <td>hierarchical_random</td>\n",
       "      <td>8</td>\n",
       "      <td>0.057500</td>\n",
       "      <td>0.019059</td>\n",
       "      <td>0.50950</td>\n",
       "      <td>0.082590</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>BiGRU</td>\n",
       "      <td>pretrained</td>\n",
       "      <td>2</td>\n",
       "      <td>0.057000</td>\n",
       "      <td>0.266830</td>\n",
       "      <td>0.50600</td>\n",
       "      <td>0.228712</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>BiGRU</td>\n",
       "      <td>pretrained</td>\n",
       "      <td>4</td>\n",
       "      <td>0.065500</td>\n",
       "      <td>0.031766</td>\n",
       "      <td>0.52950</td>\n",
       "      <td>0.057178</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>BiGRU</td>\n",
       "      <td>pretrained</td>\n",
       "      <td>8</td>\n",
       "      <td>0.065500</td>\n",
       "      <td>0.019059</td>\n",
       "      <td>0.52600</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>BiGRU</td>\n",
       "      <td>random</td>\n",
       "      <td>2</td>\n",
       "      <td>0.083500</td>\n",
       "      <td>0.031766</td>\n",
       "      <td>0.52200</td>\n",
       "      <td>0.050825</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>BiGRU</td>\n",
       "      <td>random</td>\n",
       "      <td>4</td>\n",
       "      <td>0.079000</td>\n",
       "      <td>0.025412</td>\n",
       "      <td>0.52300</td>\n",
       "      <td>0.050825</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>BiGRU</td>\n",
       "      <td>random</td>\n",
       "      <td>8</td>\n",
       "      <td>0.075000</td>\n",
       "      <td>0.012706</td>\n",
       "      <td>0.51700</td>\n",
       "      <td>0.038119</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>BiLSTM</td>\n",
       "      <td>hierarchical_pretrained</td>\n",
       "      <td>2</td>\n",
       "      <td>0.074000</td>\n",
       "      <td>0.063531</td>\n",
       "      <td>0.54400</td>\n",
       "      <td>0.012706</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>BiLSTM</td>\n",
       "      <td>hierarchical_pretrained</td>\n",
       "      <td>4</td>\n",
       "      <td>0.067500</td>\n",
       "      <td>0.120709</td>\n",
       "      <td>0.54000</td>\n",
       "      <td>0.063531</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>BiLSTM</td>\n",
       "      <td>hierarchical_pretrained</td>\n",
       "      <td>8</td>\n",
       "      <td>0.061500</td>\n",
       "      <td>0.006353</td>\n",
       "      <td>0.53250</td>\n",
       "      <td>0.006353</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>BiLSTM</td>\n",
       "      <td>hierarchical_random</td>\n",
       "      <td>2</td>\n",
       "      <td>0.079500</td>\n",
       "      <td>0.006353</td>\n",
       "      <td>0.55350</td>\n",
       "      <td>0.019059</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>BiLSTM</td>\n",
       "      <td>hierarchical_random</td>\n",
       "      <td>4</td>\n",
       "      <td>0.076500</td>\n",
       "      <td>0.031766</td>\n",
       "      <td>0.54700</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>BiLSTM</td>\n",
       "      <td>hierarchical_random</td>\n",
       "      <td>8</td>\n",
       "      <td>0.057000</td>\n",
       "      <td>0.050825</td>\n",
       "      <td>0.52650</td>\n",
       "      <td>0.082590</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>BiLSTM</td>\n",
       "      <td>pretrained</td>\n",
       "      <td>2</td>\n",
       "      <td>0.071500</td>\n",
       "      <td>0.031766</td>\n",
       "      <td>0.54750</td>\n",
       "      <td>0.031766</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>BiLSTM</td>\n",
       "      <td>pretrained</td>\n",
       "      <td>4</td>\n",
       "      <td>0.062000</td>\n",
       "      <td>0.088943</td>\n",
       "      <td>0.53900</td>\n",
       "      <td>0.088943</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>BiLSTM</td>\n",
       "      <td>pretrained</td>\n",
       "      <td>8</td>\n",
       "      <td>0.062000</td>\n",
       "      <td>0.114356</td>\n",
       "      <td>0.53350</td>\n",
       "      <td>0.082590</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>BiLSTM</td>\n",
       "      <td>random</td>\n",
       "      <td>2</td>\n",
       "      <td>0.072500</td>\n",
       "      <td>0.044472</td>\n",
       "      <td>0.54250</td>\n",
       "      <td>0.019059</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>BiLSTM</td>\n",
       "      <td>random</td>\n",
       "      <td>4</td>\n",
       "      <td>0.073500</td>\n",
       "      <td>0.044472</td>\n",
       "      <td>0.53950</td>\n",
       "      <td>0.031766</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>BiLSTM</td>\n",
       "      <td>random</td>\n",
       "      <td>8</td>\n",
       "      <td>0.072500</td>\n",
       "      <td>0.057178</td>\n",
       "      <td>0.53550</td>\n",
       "      <td>0.019059</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>CLF</td>\n",
       "      <td>hierarchical_pretrained</td>\n",
       "      <td>2</td>\n",
       "      <td>0.065000</td>\n",
       "      <td>0.101650</td>\n",
       "      <td>0.55350</td>\n",
       "      <td>0.069884</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>CLF</td>\n",
       "      <td>hierarchical_pretrained</td>\n",
       "      <td>4</td>\n",
       "      <td>0.064500</td>\n",
       "      <td>0.082590</td>\n",
       "      <td>0.55300</td>\n",
       "      <td>0.012706</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>CLF</td>\n",
       "      <td>hierarchical_pretrained</td>\n",
       "      <td>8</td>\n",
       "      <td>0.068500</td>\n",
       "      <td>0.069884</td>\n",
       "      <td>0.54400</td>\n",
       "      <td>0.203299</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>CLF</td>\n",
       "      <td>hierarchical_random</td>\n",
       "      <td>2</td>\n",
       "      <td>0.045000</td>\n",
       "      <td>0.088943</td>\n",
       "      <td>0.51350</td>\n",
       "      <td>0.247771</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>CLF</td>\n",
       "      <td>hierarchical_random</td>\n",
       "      <td>4</td>\n",
       "      <td>0.059000</td>\n",
       "      <td>0.152474</td>\n",
       "      <td>0.53500</td>\n",
       "      <td>0.152474</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>CLF</td>\n",
       "      <td>hierarchical_random</td>\n",
       "      <td>8</td>\n",
       "      <td>0.065500</td>\n",
       "      <td>0.006353</td>\n",
       "      <td>0.54700</td>\n",
       "      <td>0.012706</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>CLF</td>\n",
       "      <td>pretrained</td>\n",
       "      <td>2</td>\n",
       "      <td>0.059500</td>\n",
       "      <td>0.146121</td>\n",
       "      <td>0.54800</td>\n",
       "      <td>0.216005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>CLF</td>\n",
       "      <td>pretrained</td>\n",
       "      <td>4</td>\n",
       "      <td>0.059500</td>\n",
       "      <td>0.158828</td>\n",
       "      <td>0.54800</td>\n",
       "      <td>0.241418</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>CLF</td>\n",
       "      <td>pretrained</td>\n",
       "      <td>8</td>\n",
       "      <td>0.045500</td>\n",
       "      <td>0.120709</td>\n",
       "      <td>0.52250</td>\n",
       "      <td>0.235065</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>CLF</td>\n",
       "      <td>random</td>\n",
       "      <td>2</td>\n",
       "      <td>0.057500</td>\n",
       "      <td>0.158828</td>\n",
       "      <td>0.53450</td>\n",
       "      <td>0.324008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>CLF</td>\n",
       "      <td>random</td>\n",
       "      <td>4</td>\n",
       "      <td>0.057000</td>\n",
       "      <td>0.101650</td>\n",
       "      <td>0.53350</td>\n",
       "      <td>0.120709</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>CLF</td>\n",
       "      <td>random</td>\n",
       "      <td>8</td>\n",
       "      <td>0.031000</td>\n",
       "      <td>0.088943</td>\n",
       "      <td>0.46050</td>\n",
       "      <td>0.222359</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>CNN</td>\n",
       "      <td>hierarchical_pretrained</td>\n",
       "      <td>2</td>\n",
       "      <td>0.072000</td>\n",
       "      <td>0.063531</td>\n",
       "      <td>0.51550</td>\n",
       "      <td>0.031766</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>CNN</td>\n",
       "      <td>hierarchical_pretrained</td>\n",
       "      <td>4</td>\n",
       "      <td>0.072500</td>\n",
       "      <td>0.044472</td>\n",
       "      <td>0.51350</td>\n",
       "      <td>0.019059</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>CNN</td>\n",
       "      <td>hierarchical_pretrained</td>\n",
       "      <td>6</td>\n",
       "      <td>0.063000</td>\n",
       "      <td>0.025412</td>\n",
       "      <td>0.50950</td>\n",
       "      <td>0.044472</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>CNN</td>\n",
       "      <td>hierarchical_random</td>\n",
       "      <td>2</td>\n",
       "      <td>0.070000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.50900</td>\n",
       "      <td>0.038119</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>CNN</td>\n",
       "      <td>hierarchical_random</td>\n",
       "      <td>4</td>\n",
       "      <td>0.068500</td>\n",
       "      <td>0.006353</td>\n",
       "      <td>0.50850</td>\n",
       "      <td>0.006353</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>CNN</td>\n",
       "      <td>hierarchical_random</td>\n",
       "      <td>6</td>\n",
       "      <td>0.064000</td>\n",
       "      <td>0.076237</td>\n",
       "      <td>0.49950</td>\n",
       "      <td>0.095297</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>CNN</td>\n",
       "      <td>pretrained</td>\n",
       "      <td>2</td>\n",
       "      <td>0.073000</td>\n",
       "      <td>0.038119</td>\n",
       "      <td>0.52200</td>\n",
       "      <td>0.025412</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>CNN</td>\n",
       "      <td>pretrained</td>\n",
       "      <td>4</td>\n",
       "      <td>0.070500</td>\n",
       "      <td>0.006353</td>\n",
       "      <td>0.52150</td>\n",
       "      <td>0.006353</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>CNN</td>\n",
       "      <td>pretrained</td>\n",
       "      <td>6</td>\n",
       "      <td>0.023000</td>\n",
       "      <td>0.038119</td>\n",
       "      <td>0.39400</td>\n",
       "      <td>0.343068</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>CNN</td>\n",
       "      <td>random</td>\n",
       "      <td>2</td>\n",
       "      <td>0.078000</td>\n",
       "      <td>0.038119</td>\n",
       "      <td>0.50950</td>\n",
       "      <td>0.006353</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>CNN</td>\n",
       "      <td>random</td>\n",
       "      <td>4</td>\n",
       "      <td>0.003500</td>\n",
       "      <td>0.000919</td>\n",
       "      <td>0.18700</td>\n",
       "      <td>0.005512</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>CNN</td>\n",
       "      <td>random</td>\n",
       "      <td>6</td>\n",
       "      <td>0.016333</td>\n",
       "      <td>0.053066</td>\n",
       "      <td>0.27200</td>\n",
       "      <td>0.352818</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     model               att_module  num_heads  f1_macro_sk_mean  \\\n",
       "0    BiGRU  hierarchical_pretrained          2          0.078000   \n",
       "1    BiGRU  hierarchical_pretrained          4          0.072500   \n",
       "2    BiGRU  hierarchical_pretrained          8          0.067000   \n",
       "3    BiGRU      hierarchical_random          2          0.074000   \n",
       "4    BiGRU      hierarchical_random          4          0.075250   \n",
       "5    BiGRU      hierarchical_random          8          0.057500   \n",
       "6    BiGRU               pretrained          2          0.057000   \n",
       "7    BiGRU               pretrained          4          0.065500   \n",
       "8    BiGRU               pretrained          8          0.065500   \n",
       "9    BiGRU                   random          2          0.083500   \n",
       "10   BiGRU                   random          4          0.079000   \n",
       "11   BiGRU                   random          8          0.075000   \n",
       "12  BiLSTM  hierarchical_pretrained          2          0.074000   \n",
       "13  BiLSTM  hierarchical_pretrained          4          0.067500   \n",
       "14  BiLSTM  hierarchical_pretrained          8          0.061500   \n",
       "15  BiLSTM      hierarchical_random          2          0.079500   \n",
       "16  BiLSTM      hierarchical_random          4          0.076500   \n",
       "17  BiLSTM      hierarchical_random          8          0.057000   \n",
       "18  BiLSTM               pretrained          2          0.071500   \n",
       "19  BiLSTM               pretrained          4          0.062000   \n",
       "20  BiLSTM               pretrained          8          0.062000   \n",
       "21  BiLSTM                   random          2          0.072500   \n",
       "22  BiLSTM                   random          4          0.073500   \n",
       "23  BiLSTM                   random          8          0.072500   \n",
       "24     CLF  hierarchical_pretrained          2          0.065000   \n",
       "25     CLF  hierarchical_pretrained          4          0.064500   \n",
       "26     CLF  hierarchical_pretrained          8          0.068500   \n",
       "27     CLF      hierarchical_random          2          0.045000   \n",
       "28     CLF      hierarchical_random          4          0.059000   \n",
       "29     CLF      hierarchical_random          8          0.065500   \n",
       "30     CLF               pretrained          2          0.059500   \n",
       "31     CLF               pretrained          4          0.059500   \n",
       "32     CLF               pretrained          8          0.045500   \n",
       "33     CLF                   random          2          0.057500   \n",
       "34     CLF                   random          4          0.057000   \n",
       "35     CLF                   random          8          0.031000   \n",
       "36     CNN  hierarchical_pretrained          2          0.072000   \n",
       "37     CNN  hierarchical_pretrained          4          0.072500   \n",
       "38     CNN  hierarchical_pretrained          6          0.063000   \n",
       "39     CNN      hierarchical_random          2          0.070000   \n",
       "40     CNN      hierarchical_random          4          0.068500   \n",
       "41     CNN      hierarchical_random          6          0.064000   \n",
       "42     CNN               pretrained          2          0.073000   \n",
       "43     CNN               pretrained          4          0.070500   \n",
       "44     CNN               pretrained          6          0.023000   \n",
       "45     CNN                   random          2          0.078000   \n",
       "46     CNN                   random          4          0.003500   \n",
       "47     CNN                   random          6          0.016333   \n",
       "\n",
       "    f1_macro_sk_ci_95  f1_micro_sk_mean  f1_micro_sk_ci_95  \n",
       "0            0.007234           0.52025           0.013210  \n",
       "1            0.000919           0.52025           0.003528  \n",
       "2            0.038119           0.52150           0.031766  \n",
       "3            0.027222           0.51475           0.030146  \n",
       "4            0.015503           0.51750           0.022068  \n",
       "5            0.019059           0.50950           0.082590  \n",
       "6            0.266830           0.50600           0.228712  \n",
       "7            0.031766           0.52950           0.057178  \n",
       "8            0.019059           0.52600           0.000000  \n",
       "9            0.031766           0.52200           0.050825  \n",
       "10           0.025412           0.52300           0.050825  \n",
       "11           0.012706           0.51700           0.038119  \n",
       "12           0.063531           0.54400           0.012706  \n",
       "13           0.120709           0.54000           0.063531  \n",
       "14           0.006353           0.53250           0.006353  \n",
       "15           0.006353           0.55350           0.019059  \n",
       "16           0.031766           0.54700           0.000000  \n",
       "17           0.050825           0.52650           0.082590  \n",
       "18           0.031766           0.54750           0.031766  \n",
       "19           0.088943           0.53900           0.088943  \n",
       "20           0.114356           0.53350           0.082590  \n",
       "21           0.044472           0.54250           0.019059  \n",
       "22           0.044472           0.53950           0.031766  \n",
       "23           0.057178           0.53550           0.019059  \n",
       "24           0.101650           0.55350           0.069884  \n",
       "25           0.082590           0.55300           0.012706  \n",
       "26           0.069884           0.54400           0.203299  \n",
       "27           0.088943           0.51350           0.247771  \n",
       "28           0.152474           0.53500           0.152474  \n",
       "29           0.006353           0.54700           0.012706  \n",
       "30           0.146121           0.54800           0.216005  \n",
       "31           0.158828           0.54800           0.241418  \n",
       "32           0.120709           0.52250           0.235065  \n",
       "33           0.158828           0.53450           0.324008  \n",
       "34           0.101650           0.53350           0.120709  \n",
       "35           0.088943           0.46050           0.222359  \n",
       "36           0.063531           0.51550           0.031766  \n",
       "37           0.044472           0.51350           0.019059  \n",
       "38           0.025412           0.50950           0.044472  \n",
       "39           0.000000           0.50900           0.038119  \n",
       "40           0.006353           0.50850           0.006353  \n",
       "41           0.076237           0.49950           0.095297  \n",
       "42           0.038119           0.52200           0.025412  \n",
       "43           0.006353           0.52150           0.006353  \n",
       "44           0.038119           0.39400           0.343068  \n",
       "45           0.038119           0.50950           0.006353  \n",
       "46           0.000919           0.18700           0.005512  \n",
       "47           0.053066           0.27200           0.352818  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load Multihead Label-Attention Results for MIMIC-III-Full\n",
    "df_full_mh = pd.read_excel(os.path.join(path_results, 'results_section_C', 'MimicFull_MH_scores.xlsx'))\n",
    "# File contains experiments performed with wrong data\n",
    "df_full_mh = df_full_mh[df_full_mh['Model']!='CLF']\n",
    "# Load correct results for CLF\n",
    "df_full_mh_clf = pd.read_excel(os.path.join(path_results, 'results_section_C', 'MimicFull_MH_CLF_scores.xlsx'))\n",
    "                        \n",
    "# Combine both dataframes\n",
    "df_full_mh = pd.concat([df_full_mh, df_full_mh_clf]).sort_values(['Model', 'dataset', 'att_module', 'num_heads', 'seed'])\n",
    "\n",
    "\n",
    "# Drop all samples including results for MIMIC-III-50\n",
    "df_full_mh = df_full_mh[df_full_mh['dataset']!='Mimic50'].reset_index(drop=True)\n",
    "\n",
    "# Drop columns that are not necessary\n",
    "df_full_mh = df_full_mh.drop(['epoch', 'doc_max_len', 'batch_size', 'patience', 'embedding_scaling', 'word_embedding_dim',\n",
    "                   'kernel_sizes', 'hidden_dim', 'dropout_p', 'scale', 'multihead'], axis=1)\n",
    "# Clean dataset\n",
    "# dropping num_heads=='10' due to memory issues with certain attention\n",
    "df_full_mh = df_full_mh[~df_full_mh['num_heads'].isin([10, 16])] \n",
    "\n",
    "# Group results\n",
    "df_full_mh_grp = df_full_mh.groupby(['Model', 'att_module', 'num_heads'])[['f1_macro_sk', 'f1_micro_sk']].agg(['mean', ci_95]).reset_index()\n",
    "df_full_mh_grp\n",
    "\n",
    "# Remove multi-level indexed columns \n",
    "df_full_mh_grp.columns = df_full_mh_grp.columns.map('{0[0]}_{0[1]}'.format)\n",
    "df_full_mh_grp = df_full_mh_grp.fillna(0)\n",
    "\n",
    "df_full_mh_grp = df_full_mh_grp.rename(columns={'Model_': 'model', 'att_module_': 'att_module', 'num_heads_': 'num_heads'})\n",
    "\n",
    "df_full_mh_grp\n",
    "                   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7228b98d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>att_module</th>\n",
       "      <th>f1_macro_sk_mean</th>\n",
       "      <th>f1_macro_sk_ci_95</th>\n",
       "      <th>f1_micro_sk_mean</th>\n",
       "      <th>f1_micro_sk_ci_95</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>BiGRU</td>\n",
       "      <td>hierarchical_pretrained</td>\n",
       "      <td>0.0614</td>\n",
       "      <td>0.003787</td>\n",
       "      <td>0.533200</td>\n",
       "      <td>0.003766</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>BiGRU</td>\n",
       "      <td>hierarchical_random</td>\n",
       "      <td>0.0576</td>\n",
       "      <td>0.007481</td>\n",
       "      <td>0.525800</td>\n",
       "      <td>0.006233</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>BiGRU</td>\n",
       "      <td>pretrained</td>\n",
       "      <td>0.0622</td>\n",
       "      <td>0.005297</td>\n",
       "      <td>0.534600</td>\n",
       "      <td>0.005089</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>BiGRU</td>\n",
       "      <td>random</td>\n",
       "      <td>0.0600</td>\n",
       "      <td>0.007240</td>\n",
       "      <td>0.530800</td>\n",
       "      <td>0.006108</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>BiLSTM</td>\n",
       "      <td>hierarchical_pretrained</td>\n",
       "      <td>0.0610</td>\n",
       "      <td>0.008954</td>\n",
       "      <td>0.536800</td>\n",
       "      <td>0.008709</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>BiLSTM</td>\n",
       "      <td>hierarchical_random</td>\n",
       "      <td>0.0550</td>\n",
       "      <td>0.005757</td>\n",
       "      <td>0.522400</td>\n",
       "      <td>0.010186</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>BiLSTM</td>\n",
       "      <td>pretrained</td>\n",
       "      <td>0.0604</td>\n",
       "      <td>0.008980</td>\n",
       "      <td>0.537400</td>\n",
       "      <td>0.007481</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>BiLSTM</td>\n",
       "      <td>random</td>\n",
       "      <td>0.0608</td>\n",
       "      <td>0.006476</td>\n",
       "      <td>0.538000</td>\n",
       "      <td>0.007079</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>CLF</td>\n",
       "      <td>hierarchical_pretrained</td>\n",
       "      <td>0.0634</td>\n",
       "      <td>0.015424</td>\n",
       "      <td>0.551800</td>\n",
       "      <td>0.022409</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>CLF</td>\n",
       "      <td>hierarchical_random</td>\n",
       "      <td>0.0210</td>\n",
       "      <td>0.010828</td>\n",
       "      <td>0.358667</td>\n",
       "      <td>0.075115</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>CLF</td>\n",
       "      <td>pretrained</td>\n",
       "      <td>0.0630</td>\n",
       "      <td>0.015877</td>\n",
       "      <td>0.549800</td>\n",
       "      <td>0.021567</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>CLF</td>\n",
       "      <td>random</td>\n",
       "      <td>0.0516</td>\n",
       "      <td>0.021174</td>\n",
       "      <td>0.524000</td>\n",
       "      <td>0.057974</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>CNN</td>\n",
       "      <td>hierarchical_pretrained</td>\n",
       "      <td>0.0452</td>\n",
       "      <td>0.023533</td>\n",
       "      <td>0.455200</td>\n",
       "      <td>0.056105</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>CNN</td>\n",
       "      <td>hierarchical_random</td>\n",
       "      <td>0.0118</td>\n",
       "      <td>0.005784</td>\n",
       "      <td>0.317800</td>\n",
       "      <td>0.038745</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>CNN</td>\n",
       "      <td>pretrained</td>\n",
       "      <td>0.0482</td>\n",
       "      <td>0.008665</td>\n",
       "      <td>0.488800</td>\n",
       "      <td>0.009350</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>CNN</td>\n",
       "      <td>random</td>\n",
       "      <td>0.0380</td>\n",
       "      <td>0.012754</td>\n",
       "      <td>0.469800</td>\n",
       "      <td>0.024051</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     model               att_module  f1_macro_sk_mean  f1_macro_sk_ci_95  \\\n",
       "1    BiGRU  hierarchical_pretrained            0.0614           0.003787   \n",
       "2    BiGRU      hierarchical_random            0.0576           0.007481   \n",
       "3    BiGRU               pretrained            0.0622           0.005297   \n",
       "4    BiGRU                   random            0.0600           0.007240   \n",
       "7   BiLSTM  hierarchical_pretrained            0.0610           0.008954   \n",
       "8   BiLSTM      hierarchical_random            0.0550           0.005757   \n",
       "9   BiLSTM               pretrained            0.0604           0.008980   \n",
       "10  BiLSTM                   random            0.0608           0.006476   \n",
       "13     CLF  hierarchical_pretrained            0.0634           0.015424   \n",
       "14     CLF      hierarchical_random            0.0210           0.010828   \n",
       "15     CLF               pretrained            0.0630           0.015877   \n",
       "16     CLF                   random            0.0516           0.021174   \n",
       "19     CNN  hierarchical_pretrained            0.0452           0.023533   \n",
       "20     CNN      hierarchical_random            0.0118           0.005784   \n",
       "21     CNN               pretrained            0.0482           0.008665   \n",
       "22     CNN                   random            0.0380           0.012754   \n",
       "\n",
       "    f1_micro_sk_mean  f1_micro_sk_ci_95  \n",
       "1           0.533200           0.003766  \n",
       "2           0.525800           0.006233  \n",
       "3           0.534600           0.005089  \n",
       "4           0.530800           0.006108  \n",
       "7           0.536800           0.008709  \n",
       "8           0.522400           0.010186  \n",
       "9           0.537400           0.007481  \n",
       "10          0.538000           0.007079  \n",
       "13          0.551800           0.022409  \n",
       "14          0.358667           0.075115  \n",
       "15          0.549800           0.021567  \n",
       "16          0.524000           0.057974  \n",
       "19          0.455200           0.056105  \n",
       "20          0.317800           0.038745  \n",
       "21          0.488800           0.009350  \n",
       "22          0.469800           0.024051  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dff_grp2 = df_full_grp[~df_full_grp['att_module'].isin(['baseline', 'target'])].copy()\n",
    "\n",
    "dff_grp2 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "65d1e38a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CNN and random\n",
      "Number of Heads: 2\n",
      "Single-Head Macro UB: 0.11611861420929631\n",
      "Single-Head Macro LB: 0.03988138579070369\n",
      "Single-Head Micro UB: 0.5158531023682161\n",
      "Single-Head Micro LB: 0.503146897631784\n",
      "Number of Heads: 4\n",
      "Single-Head Macro UB: 0.0044186931155187\n",
      "Single-Head Macro LB: 0.0025813068844813005\n",
      "Single-Head Micro UB: 0.1925121586931122\n",
      "Single-Head Micro LB: 0.1814878413068878\n",
      "Number of Heads: 6\n",
      "Single-Head Macro UB: 0.06939938366890572\n",
      "Single-Head Macro LB: -0.03673271700223904\n",
      "Single-Head Micro UB: 0.6248175238527245\n",
      "Single-Head Micro LB: -0.08081752385272445\n",
      "CNN and pretrained\n",
      "Number of Heads: 2\n",
      "Single-Head Macro UB: 0.11111861420929624\n",
      "Single-Head Macro LB: 0.03488138579070378\n",
      "Single-Head Micro UB: 0.5474124094728642\n",
      "Single-Head Micro LB: 0.49658759052713586\n",
      "Number of Heads: 4\n",
      "Single-Head Macro UB: 0.07685310236821596\n",
      "Single-Head Macro LB: 0.06414689763178405\n",
      "Single-Head Micro UB: 0.5278531023682161\n",
      "Single-Head Micro LB: 0.515146897631784\n",
      "Number of Heads: 6\n",
      "Single-Head Macro UB: 0.061118614209296276\n",
      "Single-Head Macro LB: -0.015118614209296277\n",
      "Single-Head Micro UB: 0.7370675278836665\n",
      "Single-Head Micro LB: 0.05093247211633356\n",
      "CNN and hierarchical_random\n",
      "Number of Heads: 2\n",
      "Single-Head Macro UB: 0.07\n",
      "Single-Head Macro LB: 0.07\n",
      "Single-Head Micro UB: 0.5471186142092963\n",
      "Single-Head Micro LB: 0.4708813857907037\n",
      "Number of Heads: 4\n",
      "Single-Head Macro UB: 0.07485310236821606\n",
      "Single-Head Macro LB: 0.06214689763178395\n",
      "Single-Head Micro UB: 0.514853102368216\n",
      "Single-Head Micro LB: 0.5021468976317839\n",
      "Number of Heads: 6\n",
      "Single-Head Macro UB: 0.1402372284185926\n",
      "Single-Head Macro LB: -0.012237228418592594\n",
      "Single-Head Micro UB: 0.5947965355232407\n",
      "Single-Head Micro LB: 0.40420346447675926\n",
      "CNN and hierarchical_pretrained\n",
      "Number of Heads: 2\n",
      "Single-Head Macro UB: 0.13553102368216047\n",
      "Single-Head Macro LB: 0.00846897631783955\n",
      "Single-Head Micro UB: 0.5472655118410803\n",
      "Single-Head Micro LB: 0.48373448815891984\n",
      "Number of Heads: 4\n",
      "Single-Head Macro UB: 0.11697171657751229\n",
      "Single-Head Macro LB: 0.028028283422487726\n",
      "Single-Head Micro UB: 0.5325593071046483\n",
      "Single-Head Micro LB: 0.49444069289535186\n",
      "Number of Heads: 6\n",
      "Single-Head Macro UB: 0.08841240947286422\n",
      "Single-Head Macro LB: 0.037587590527135784\n",
      "Single-Head Micro UB: 0.5539717165775124\n",
      "Single-Head Micro LB: 0.4650282834224877\n",
      "BiGRU and random\n",
      "Number of Heads: 2\n",
      "Single-Head Macro UB: 0.11526551184108016\n",
      "Single-Head Macro LB: 0.05173448815891982\n",
      "Single-Head Micro UB: 0.5728248189457285\n",
      "Single-Head Micro LB: 0.4711751810542716\n",
      "Number of Heads: 4\n",
      "Single-Head Macro UB: 0.10441240947286422\n",
      "Single-Head Macro LB: 0.053587590527135784\n",
      "Single-Head Micro UB: 0.5738248189457285\n",
      "Single-Head Micro LB: 0.4721751810542716\n",
      "Number of Heads: 8\n",
      "Single-Head Macro UB: 0.0877062047364321\n",
      "Single-Head Macro LB: 0.06229379526356789\n",
      "Single-Head Micro UB: 0.5551186142092963\n",
      "Single-Head Micro LB: 0.4788813857907037\n",
      "BiGRU and pretrained\n",
      "Number of Heads: 2\n",
      "Single-Head Macro UB: 0.323830299465074\n",
      "Single-Head Macro LB: -0.20983029946507403\n",
      "Single-Head Micro UB: 0.7347116852557779\n",
      "Single-Head Micro LB: 0.2772883147442221\n",
      "Number of Heads: 4\n",
      "Single-Head Macro UB: 0.09726551184108026\n",
      "Single-Head Macro LB: 0.033734488158919745\n",
      "Single-Head Micro UB: 0.5866779213139446\n",
      "Single-Head Micro LB: 0.4723220786860556\n",
      "Number of Heads: 8\n",
      "Single-Head Macro UB: 0.08455930710464817\n",
      "Single-Head Macro LB: 0.04644069289535184\n",
      "Single-Head Micro UB: 0.526\n",
      "Single-Head Micro LB: 0.526\n",
      "BiGRU and hierarchical_random\n",
      "Number of Heads: 2\n",
      "Single-Head Macro UB: 0.10122185521892799\n",
      "Single-Head Macro LB: 0.046778144781072006\n",
      "Single-Head Micro UB: 0.5448958755613424\n",
      "Single-Head Micro LB: 0.48460412443865764\n",
      "Number of Heads: 4\n",
      "Single-Head Macro UB: 0.09075252099765678\n",
      "Single-Head Macro LB: 0.059747479002343215\n",
      "Single-Head Micro UB: 0.5395677659125101\n",
      "Single-Head Micro LB: 0.49543223408749004\n",
      "Number of Heads: 8\n",
      "Single-Head Macro UB: 0.07655930710464812\n",
      "Single-Head Macro LB: 0.038440692895351875\n",
      "Single-Head Micro UB: 0.5920903307868087\n",
      "Single-Head Micro LB: 0.4269096692131914\n",
      "BiGRU and hierarchical_pretrained\n",
      "Number of Heads: 2\n",
      "Single-Head Macro UB: 0.08523379682539468\n",
      "Single-Head Macro LB: 0.07076620317460532\n",
      "Single-Head Micro UB: 0.5334597081013804\n",
      "Single-Head Micro LB: 0.5070402918986195\n",
      "Number of Heads: 4\n",
      "Single-Head Macro UB: 0.0734186931155187\n",
      "Single-Head Macro LB: 0.07158130688448129\n",
      "Single-Head Micro UB: 0.5237783078589313\n",
      "Single-Head Micro LB: 0.5167216921410687\n",
      "Number of Heads: 8\n",
      "Single-Head Macro UB: 0.10511861420929633\n",
      "Single-Head Macro LB: 0.02888138579070368\n",
      "Single-Head Micro UB: 0.5532655118410803\n",
      "Single-Head Micro LB: 0.48973448815891985\n",
      "BiLSTM and random\n",
      "Number of Heads: 2\n",
      "Single-Head Macro UB: 0.11697171657751229\n",
      "Single-Head Macro LB: 0.028028283422487726\n",
      "Single-Head Micro UB: 0.5615593071046482\n",
      "Single-Head Micro LB: 0.5234406928953518\n",
      "Number of Heads: 4\n",
      "Single-Head Macro UB: 0.11797171657751229\n",
      "Single-Head Macro LB: 0.029028283422487727\n",
      "Single-Head Micro UB: 0.5712655118410803\n",
      "Single-Head Micro LB: 0.5077344881589199\n",
      "Number of Heads: 8\n",
      "Single-Head Macro UB: 0.1296779213139444\n",
      "Single-Head Macro LB: 0.015322078686055618\n",
      "Single-Head Micro UB: 0.5545593071046483\n",
      "Single-Head Micro LB: 0.5164406928953519\n",
      "BiLSTM and pretrained\n",
      "Number of Heads: 2\n",
      "Single-Head Macro UB: 0.10326551184108018\n",
      "Single-Head Macro LB: 0.039734488158919834\n",
      "Single-Head Micro UB: 0.5792655118410803\n",
      "Single-Head Micro LB: 0.5157344881589199\n",
      "Number of Heads: 4\n",
      "Single-Head Macro UB: 0.15094343315502468\n",
      "Single-Head Macro LB: -0.026943433155024676\n",
      "Single-Head Micro UB: 0.6279434331550248\n",
      "Single-Head Micro LB: 0.4500565668449753\n",
      "Number of Heads: 8\n",
      "Single-Head Macro UB: 0.17635584262788884\n",
      "Single-Head Macro LB: -0.05235584262788884\n",
      "Single-Head Micro UB: 0.6160903307868087\n",
      "Single-Head Micro LB: 0.4509096692131914\n",
      "BiLSTM and hierarchical_random\n",
      "Number of Heads: 2\n",
      "Single-Head Macro UB: 0.08585310236821606\n",
      "Single-Head Macro LB: 0.07314689763178395\n",
      "Single-Head Micro UB: 0.5725593071046483\n",
      "Single-Head Micro LB: 0.5344406928953519\n",
      "Number of Heads: 4\n",
      "Single-Head Macro UB: 0.10826551184108027\n",
      "Single-Head Macro LB: 0.04473448815891973\n",
      "Single-Head Micro UB: 0.547\n",
      "Single-Head Micro LB: 0.547\n",
      "Number of Heads: 8\n",
      "Single-Head Macro UB: 0.10782481894572837\n",
      "Single-Head Macro LB: 0.006175181054271617\n",
      "Single-Head Micro UB: 0.6090903307868086\n",
      "Single-Head Micro LB: 0.4439096692131913\n",
      "BiLSTM and hierarchical_pretrained\n",
      "Number of Heads: 2\n",
      "Single-Head Macro UB: 0.13753102368216047\n",
      "Single-Head Macro LB: 0.010468976317839551\n",
      "Single-Head Micro UB: 0.5567062047364322\n",
      "Single-Head Micro LB: 0.5312937952635679\n",
      "Number of Heads: 4\n",
      "Single-Head Macro UB: 0.18820894499610488\n",
      "Single-Head Macro LB: -0.05320894499610487\n",
      "Single-Head Micro UB: 0.6035310236821606\n",
      "Single-Head Micro LB: 0.47646897631783947\n",
      "Number of Heads: 8\n",
      "Single-Head Macro UB: 0.06785310236821605\n",
      "Single-Head Macro LB: 0.055146897631783945\n",
      "Single-Head Micro UB: 0.538853102368216\n",
      "Single-Head Micro LB: 0.5261468976317839\n",
      "CLF and random\n",
      "Number of Heads: 2\n",
      "Single-Head Macro UB: 0.21632755920540125\n",
      "Single-Head Macro LB: -0.10132755920540126\n",
      "Single-Head Micro UB: 0.8585082207790187\n",
      "Single-Head Micro LB: 0.21049177922098128\n",
      "Number of Heads: 4\n",
      "Single-Head Macro UB: 0.15864963789145678\n",
      "Single-Head Macro LB: -0.04464963789145678\n",
      "Single-Head Micro UB: 0.654208944996105\n",
      "Single-Head Micro LB: 0.4127910550038951\n",
      "Number of Heads: 8\n",
      "Single-Head Macro UB: 0.11994343315502466\n",
      "Single-Head Macro LB: -0.05794343315502466\n",
      "Single-Head Micro UB: 0.6828585828875615\n",
      "Single-Head Micro LB: 0.23814141711243852\n",
      "CLF and pretrained\n",
      "Number of Heads: 2\n",
      "Single-Head Macro UB: 0.20562135446896904\n",
      "Single-Head Macro LB: -0.08662135446896904\n",
      "Single-Head Micro UB: 0.7640054805193451\n",
      "Single-Head Micro LB: 0.33199451948065495\n",
      "Number of Heads: 4\n",
      "Single-Head Macro UB: 0.21832755920540114\n",
      "Single-Head Macro LB: -0.09932755920540115\n",
      "Single-Head Micro UB: 0.7894178899922093\n",
      "Single-Head Micro LB: 0.3065821100077908\n",
      "Number of Heads: 8\n",
      "Single-Head Macro UB: 0.16620894499610492\n",
      "Single-Head Macro LB: -0.07520894499610492\n",
      "Single-Head Micro UB: 0.7575647876239939\n",
      "Single-Head Micro LB: 0.287435212376006\n",
      "CLF and hierarchical_random\n",
      "Number of Heads: 2\n",
      "Single-Head Macro UB: 0.13394343315502466\n",
      "Single-Head Macro LB: -0.043943433155024664\n",
      "Single-Head Micro UB: 0.7612709923604262\n",
      "Single-Head Micro LB: 0.26572900763957397\n",
      "Number of Heads: 4\n",
      "Single-Head Macro UB: 0.2114744568371851\n",
      "Single-Head Macro LB: -0.09347445683718511\n",
      "Single-Head Micro UB: 0.6874744568371853\n",
      "Single-Head Micro LB: 0.38252554316281473\n",
      "Number of Heads: 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Single-Head Macro UB: 0.07185310236821606\n",
      "Single-Head Macro LB: 0.05914689763178395\n",
      "Single-Head Micro UB: 0.5597062047364322\n",
      "Single-Head Micro LB: 0.5342937952635679\n",
      "CLF and hierarchical_pretrained\n",
      "Number of Heads: 2\n",
      "Single-Head Macro UB: 0.1666496378914567\n",
      "Single-Head Macro LB: -0.0366496378914567\n",
      "Single-Head Micro UB: 0.6233841260503767\n",
      "Single-Head Micro LB: 0.48361587394962346\n",
      "Number of Heads: 4\n",
      "Single-Head Macro UB: 0.14709033078680855\n",
      "Single-Head Macro LB: -0.01809033078680855\n",
      "Single-Head Micro UB: 0.5657062047364322\n",
      "Single-Head Micro LB: 0.5402937952635679\n",
      "Number of Heads: 8\n",
      "Single-Head Macro UB: 0.13838412605037648\n",
      "Single-Head Macro LB: -0.0013841260503764663\n",
      "Single-Head Micro UB: 0.7472992757829138\n",
      "Single-Head Micro LB: 0.3407007242170863\n"
     ]
    }
   ],
   "source": [
    "# Comparison between single- and multihead performances\n",
    "models = ['CNN', 'BiGRU', 'BiLSTM', 'CLF']\n",
    "atts = ['random', 'pretrained', 'hierarchical_random', 'hierarchical_pretrained']\n",
    "\n",
    "model_col = []\n",
    "att_col = []\n",
    "nh_col = []\n",
    "macro_sig = []\n",
    "micro_sig = []\n",
    "\n",
    "macro_larger = []\n",
    "micro_larger = []\n",
    "\n",
    "\n",
    "# Remove baseline and target module\n",
    "# Retrieve data from section above\n",
    "dff_grp2 = df_full_grp[~df_full_grp['att_module'].isin(['baseline', 'target'])].copy()\n",
    "df_mh_grp2 = df_full_mh_grp.copy()\n",
    "for model in models:\n",
    "    for att in atts:\n",
    "        print(f'{model} and {att}')\n",
    "        sh_macro = dff_grp2[dff_grp2['model']==model][dff_grp2['att_module']==att]['f1_macro_sk_mean'].reset_index(drop=True)[0]\n",
    "        sh_macro_95 = dff_grp2[dff_grp2['model']==model][dff_grp2['att_module']==att]['f1_macro_sk_ci_95'].reset_index(drop=True)[0]\n",
    "\n",
    "        sh_micro = dff_grp2[dff_grp2['model']==model][dff_grp2['att_module']==att]['f1_micro_sk_mean'].reset_index(drop=True)[0]\n",
    "        sh_micro_95 = dff_grp2[dff_grp2['model']==model][dff_grp2['att_module']==att]['f1_micro_sk_ci_95'].reset_index(drop=True)[0]\n",
    "\n",
    "        sh_macro_ub = sh_macro + sh_macro_95\n",
    "        sh_macro_lb = sh_macro - sh_macro_95\n",
    "        \n",
    "        sh_micro_ub = sh_micro + sh_micro_95\n",
    "        sh_micro_lb = sh_micro - sh_micro_95\n",
    "    \n",
    "        if model == 'CNN':\n",
    "            nh = [2, 4, 6]\n",
    "        else:\n",
    "            nh = [2, 4, 8]\n",
    "        for n in nh:\n",
    "            print(f'Number of Heads: {n}')\n",
    "            mh_macro = df_mh_grp2[df_mh_grp2['model']==model][df_mh_grp2['att_module']==att][df_mh_grp2['num_heads']==n]['f1_macro_sk_mean'].reset_index(drop=True)[0]\n",
    "            mh_macro_95 = df_mh_grp2[df_mh_grp2['model']==model][df_mh_grp2['att_module']==att][df_mh_grp2['num_heads']==n]['f1_macro_sk_ci_95'].reset_index(drop=True)[0]\n",
    "            mh_micro = df_mh_grp2[df_mh_grp2['model']==model][df_mh_grp2['att_module']==att][df_mh_grp2['num_heads']==n]['f1_micro_sk_mean'].reset_index(drop=True)[0]\n",
    "            mh_micro_95 = df_mh_grp2[df_mh_grp2['model']==model][df_mh_grp2['att_module']==att][df_mh_grp2['num_heads']==n]['f1_micro_sk_ci_95'].reset_index(drop=True)[0]\n",
    "            \n",
    "            mh_macro_ub = mh_macro + mh_macro_95\n",
    "            mh_macro_lb = mh_macro - mh_macro_95\n",
    "\n",
    "            mh_micro_ub = mh_micro + mh_micro_95\n",
    "            mh_micro_lb = mh_micro - mh_micro_95\n",
    "            \n",
    "            \n",
    "            print(f'Single-Head Macro UB: {mh_macro_ub}')\n",
    "            print(f'Single-Head Macro LB: {mh_macro_lb}')\n",
    "\n",
    "            print(f'Single-Head Micro UB: {mh_micro_ub}')\n",
    "            print(f'Single-Head Micro LB: {mh_micro_lb}')\n",
    "    \n",
    "            \n",
    "            if (mh_macro_ub < sh_macro_lb) or (mh_macro_lb > sh_macro_ub):\n",
    "                macro_significance = True\n",
    "            else:\n",
    "                macro_significance = False\n",
    "            \n",
    "            if (mh_micro_ub < sh_micro_lb) or (mh_micro_lb > sh_micro_ub):\n",
    "                micro_significance = True\n",
    "            else:\n",
    "                micro_significance = False\n",
    "                \n",
    "            if mh_macro > sh_macro:\n",
    "                mh_larger_sh_macro = True\n",
    "            else:\n",
    "                mh_larger_sh_macro = False\n",
    "                \n",
    "            if mh_micro > sh_micro:\n",
    "                mh_larger_sh_micro = True\n",
    "            else:\n",
    "                mh_larger_sh_micro = False\n",
    "                        \n",
    "            # Append all the information\n",
    "            \n",
    "            model_col.append(model)\n",
    "            att_col.append(att)\n",
    "            nh_col.append(n)\n",
    "            macro_sig.append(macro_significance)\n",
    "            micro_sig.append(micro_significance)\n",
    "            macro_larger.append(mh_larger_sh_macro)\n",
    "            micro_larger.append(mh_larger_sh_micro)\n",
    "            \n",
    "            \n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "7d02dfe8",
   "metadata": {},
   "outputs": [],
   "source": [
    "d = {'models': model_col, 'atts': att_col,\n",
    "    'nh': nh_col, 'macro_sig': macro_sig, 'micro_sig': micro_sig,\n",
    "    'macro_larger': macro_larger, 'micro_larger': micro_larger}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "116aec1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sig = pd.DataFrame(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ecf776e5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>models</th>\n",
       "      <th>atts</th>\n",
       "      <th>nh</th>\n",
       "      <th>macro_sig</th>\n",
       "      <th>micro_sig</th>\n",
       "      <th>macro_larger</th>\n",
       "      <th>micro_larger</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>CNN</td>\n",
       "      <td>random</td>\n",
       "      <td>2</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>CNN</td>\n",
       "      <td>random</td>\n",
       "      <td>4</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>CNN</td>\n",
       "      <td>random</td>\n",
       "      <td>6</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>CNN</td>\n",
       "      <td>pretrained</td>\n",
       "      <td>2</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>CNN</td>\n",
       "      <td>pretrained</td>\n",
       "      <td>4</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>CNN</td>\n",
       "      <td>pretrained</td>\n",
       "      <td>6</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>CNN</td>\n",
       "      <td>hierarchical_random</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>CNN</td>\n",
       "      <td>hierarchical_random</td>\n",
       "      <td>4</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>CNN</td>\n",
       "      <td>hierarchical_random</td>\n",
       "      <td>6</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>CNN</td>\n",
       "      <td>hierarchical_pretrained</td>\n",
       "      <td>2</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>CNN</td>\n",
       "      <td>hierarchical_pretrained</td>\n",
       "      <td>4</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>CNN</td>\n",
       "      <td>hierarchical_pretrained</td>\n",
       "      <td>6</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>BiGRU</td>\n",
       "      <td>random</td>\n",
       "      <td>2</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>BiGRU</td>\n",
       "      <td>random</td>\n",
       "      <td>4</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>BiGRU</td>\n",
       "      <td>random</td>\n",
       "      <td>8</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>BiGRU</td>\n",
       "      <td>pretrained</td>\n",
       "      <td>2</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>BiGRU</td>\n",
       "      <td>pretrained</td>\n",
       "      <td>4</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>BiGRU</td>\n",
       "      <td>pretrained</td>\n",
       "      <td>8</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>BiGRU</td>\n",
       "      <td>hierarchical_random</td>\n",
       "      <td>2</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>BiGRU</td>\n",
       "      <td>hierarchical_random</td>\n",
       "      <td>4</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>BiGRU</td>\n",
       "      <td>hierarchical_random</td>\n",
       "      <td>8</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>BiGRU</td>\n",
       "      <td>hierarchical_pretrained</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>BiGRU</td>\n",
       "      <td>hierarchical_pretrained</td>\n",
       "      <td>4</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>BiGRU</td>\n",
       "      <td>hierarchical_pretrained</td>\n",
       "      <td>8</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>BiLSTM</td>\n",
       "      <td>random</td>\n",
       "      <td>2</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>BiLSTM</td>\n",
       "      <td>random</td>\n",
       "      <td>4</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>BiLSTM</td>\n",
       "      <td>random</td>\n",
       "      <td>8</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>BiLSTM</td>\n",
       "      <td>pretrained</td>\n",
       "      <td>2</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>BiLSTM</td>\n",
       "      <td>pretrained</td>\n",
       "      <td>4</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>BiLSTM</td>\n",
       "      <td>pretrained</td>\n",
       "      <td>8</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>BiLSTM</td>\n",
       "      <td>hierarchical_random</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>BiLSTM</td>\n",
       "      <td>hierarchical_random</td>\n",
       "      <td>4</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>BiLSTM</td>\n",
       "      <td>hierarchical_random</td>\n",
       "      <td>8</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>BiLSTM</td>\n",
       "      <td>hierarchical_pretrained</td>\n",
       "      <td>2</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>BiLSTM</td>\n",
       "      <td>hierarchical_pretrained</td>\n",
       "      <td>4</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>BiLSTM</td>\n",
       "      <td>hierarchical_pretrained</td>\n",
       "      <td>8</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>CLF</td>\n",
       "      <td>random</td>\n",
       "      <td>2</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>CLF</td>\n",
       "      <td>random</td>\n",
       "      <td>4</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>CLF</td>\n",
       "      <td>random</td>\n",
       "      <td>8</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>CLF</td>\n",
       "      <td>pretrained</td>\n",
       "      <td>2</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>CLF</td>\n",
       "      <td>pretrained</td>\n",
       "      <td>4</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>CLF</td>\n",
       "      <td>pretrained</td>\n",
       "      <td>8</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>CLF</td>\n",
       "      <td>hierarchical_random</td>\n",
       "      <td>2</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>CLF</td>\n",
       "      <td>hierarchical_random</td>\n",
       "      <td>4</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>CLF</td>\n",
       "      <td>hierarchical_random</td>\n",
       "      <td>8</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>CLF</td>\n",
       "      <td>hierarchical_pretrained</td>\n",
       "      <td>2</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>CLF</td>\n",
       "      <td>hierarchical_pretrained</td>\n",
       "      <td>4</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>CLF</td>\n",
       "      <td>hierarchical_pretrained</td>\n",
       "      <td>8</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    models                     atts  nh  macro_sig  micro_sig  macro_larger  \\\n",
       "0      CNN                   random   2      False       True          True   \n",
       "1      CNN                   random   4       True       True         False   \n",
       "2      CNN                   random   6      False      False         False   \n",
       "3      CNN               pretrained   2      False      False          True   \n",
       "4      CNN               pretrained   4       True       True          True   \n",
       "5      CNN               pretrained   6      False      False         False   \n",
       "6      CNN      hierarchical_random   2       True       True          True   \n",
       "7      CNN      hierarchical_random   4       True       True          True   \n",
       "8      CNN      hierarchical_random   6      False       True          True   \n",
       "9      CNN  hierarchical_pretrained   2      False      False          True   \n",
       "10     CNN  hierarchical_pretrained   4      False      False          True   \n",
       "11     CNN  hierarchical_pretrained   6      False      False          True   \n",
       "12   BiGRU                   random   2      False      False          True   \n",
       "13   BiGRU                   random   4      False      False          True   \n",
       "14   BiGRU                   random   8      False      False          True   \n",
       "15   BiGRU               pretrained   2      False      False         False   \n",
       "16   BiGRU               pretrained   4      False      False          True   \n",
       "17   BiGRU               pretrained   8      False       True          True   \n",
       "18   BiGRU      hierarchical_random   2      False      False          True   \n",
       "19   BiGRU      hierarchical_random   4      False      False          True   \n",
       "20   BiGRU      hierarchical_random   8      False      False         False   \n",
       "21   BiGRU  hierarchical_pretrained   2       True      False          True   \n",
       "22   BiGRU  hierarchical_pretrained   4       True       True          True   \n",
       "23   BiGRU  hierarchical_pretrained   8      False      False          True   \n",
       "24  BiLSTM                   random   2      False      False          True   \n",
       "25  BiLSTM                   random   4      False      False          True   \n",
       "26  BiLSTM                   random   8      False      False          True   \n",
       "27  BiLSTM               pretrained   2      False      False          True   \n",
       "28  BiLSTM               pretrained   4      False      False          True   \n",
       "29  BiLSTM               pretrained   8      False      False          True   \n",
       "30  BiLSTM      hierarchical_random   2       True       True          True   \n",
       "31  BiLSTM      hierarchical_random   4      False       True          True   \n",
       "32  BiLSTM      hierarchical_random   8      False      False          True   \n",
       "33  BiLSTM  hierarchical_pretrained   2      False      False          True   \n",
       "34  BiLSTM  hierarchical_pretrained   4      False      False          True   \n",
       "35  BiLSTM  hierarchical_pretrained   8      False      False          True   \n",
       "36     CLF                   random   2      False      False          True   \n",
       "37     CLF                   random   4      False      False          True   \n",
       "38     CLF                   random   8      False      False         False   \n",
       "39     CLF               pretrained   2      False      False         False   \n",
       "40     CLF               pretrained   4      False      False         False   \n",
       "41     CLF               pretrained   8      False      False         False   \n",
       "42     CLF      hierarchical_random   2      False      False          True   \n",
       "43     CLF      hierarchical_random   4      False      False          True   \n",
       "44     CLF      hierarchical_random   8       True       True          True   \n",
       "45     CLF  hierarchical_pretrained   2      False      False          True   \n",
       "46     CLF  hierarchical_pretrained   4      False      False          True   \n",
       "47     CLF  hierarchical_pretrained   8      False      False          True   \n",
       "\n",
       "    micro_larger  \n",
       "0           True  \n",
       "1          False  \n",
       "2          False  \n",
       "3           True  \n",
       "4           True  \n",
       "5          False  \n",
       "6           True  \n",
       "7           True  \n",
       "8           True  \n",
       "9           True  \n",
       "10          True  \n",
       "11          True  \n",
       "12         False  \n",
       "13         False  \n",
       "14         False  \n",
       "15         False  \n",
       "16         False  \n",
       "17         False  \n",
       "18         False  \n",
       "19         False  \n",
       "20         False  \n",
       "21         False  \n",
       "22         False  \n",
       "23         False  \n",
       "24          True  \n",
       "25          True  \n",
       "26         False  \n",
       "27          True  \n",
       "28          True  \n",
       "29         False  \n",
       "30          True  \n",
       "31          True  \n",
       "32          True  \n",
       "33          True  \n",
       "34          True  \n",
       "35         False  \n",
       "36          True  \n",
       "37          True  \n",
       "38         False  \n",
       "39         False  \n",
       "40         False  \n",
       "41         False  \n",
       "42          True  \n",
       "43          True  \n",
       "44          True  \n",
       "45          True  \n",
       "46          True  \n",
       "47         False  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_sig"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e18c3911",
   "metadata": {},
   "source": [
    "# Results: MIMIC-III-50 - Multihead"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "f4306953",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>att_module</th>\n",
       "      <th>num_heads</th>\n",
       "      <th>f1_macro_sk_mean</th>\n",
       "      <th>f1_macro_sk_ci_95</th>\n",
       "      <th>f1_micro_sk_mean</th>\n",
       "      <th>f1_micro_sk_ci_95</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>BiGRU</td>\n",
       "      <td>hierarchical_pretrained</td>\n",
       "      <td>2</td>\n",
       "      <td>0.543200</td>\n",
       "      <td>0.008183</td>\n",
       "      <td>0.644800</td>\n",
       "      <td>0.005508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>BiGRU</td>\n",
       "      <td>hierarchical_pretrained</td>\n",
       "      <td>4</td>\n",
       "      <td>0.555600</td>\n",
       "      <td>0.008684</td>\n",
       "      <td>0.652400</td>\n",
       "      <td>0.004614</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>BiGRU</td>\n",
       "      <td>hierarchical_pretrained</td>\n",
       "      <td>8</td>\n",
       "      <td>0.541900</td>\n",
       "      <td>0.009102</td>\n",
       "      <td>0.645600</td>\n",
       "      <td>0.006567</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>BiGRU</td>\n",
       "      <td>hierarchical_pretrained</td>\n",
       "      <td>16</td>\n",
       "      <td>0.529000</td>\n",
       "      <td>0.007675</td>\n",
       "      <td>0.639400</td>\n",
       "      <td>0.004924</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>BiGRU</td>\n",
       "      <td>hierarchical_random</td>\n",
       "      <td>2</td>\n",
       "      <td>0.552600</td>\n",
       "      <td>0.018367</td>\n",
       "      <td>0.650200</td>\n",
       "      <td>0.008255</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>BiGRU</td>\n",
       "      <td>hierarchical_random</td>\n",
       "      <td>4</td>\n",
       "      <td>0.549200</td>\n",
       "      <td>0.024290</td>\n",
       "      <td>0.646200</td>\n",
       "      <td>0.014780</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>BiGRU</td>\n",
       "      <td>hierarchical_random</td>\n",
       "      <td>8</td>\n",
       "      <td>0.546000</td>\n",
       "      <td>0.010931</td>\n",
       "      <td>0.644000</td>\n",
       "      <td>0.002323</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>BiGRU</td>\n",
       "      <td>hierarchical_random</td>\n",
       "      <td>16</td>\n",
       "      <td>0.533200</td>\n",
       "      <td>0.016966</td>\n",
       "      <td>0.634600</td>\n",
       "      <td>0.008123</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>BiGRU</td>\n",
       "      <td>pretrained</td>\n",
       "      <td>2</td>\n",
       "      <td>0.525800</td>\n",
       "      <td>0.018320</td>\n",
       "      <td>0.635400</td>\n",
       "      <td>0.012342</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>BiGRU</td>\n",
       "      <td>pretrained</td>\n",
       "      <td>4</td>\n",
       "      <td>0.537400</td>\n",
       "      <td>0.033715</td>\n",
       "      <td>0.643200</td>\n",
       "      <td>0.017808</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>BiGRU</td>\n",
       "      <td>pretrained</td>\n",
       "      <td>8</td>\n",
       "      <td>0.541800</td>\n",
       "      <td>0.027687</td>\n",
       "      <td>0.644800</td>\n",
       "      <td>0.011955</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>BiGRU</td>\n",
       "      <td>pretrained</td>\n",
       "      <td>16</td>\n",
       "      <td>0.530600</td>\n",
       "      <td>0.024562</td>\n",
       "      <td>0.639000</td>\n",
       "      <td>0.015853</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>BiGRU</td>\n",
       "      <td>random</td>\n",
       "      <td>2</td>\n",
       "      <td>0.532250</td>\n",
       "      <td>0.015986</td>\n",
       "      <td>0.636625</td>\n",
       "      <td>0.006303</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>BiGRU</td>\n",
       "      <td>random</td>\n",
       "      <td>4</td>\n",
       "      <td>0.523286</td>\n",
       "      <td>0.017226</td>\n",
       "      <td>0.634143</td>\n",
       "      <td>0.008088</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>BiGRU</td>\n",
       "      <td>random</td>\n",
       "      <td>8</td>\n",
       "      <td>0.501000</td>\n",
       "      <td>0.017717</td>\n",
       "      <td>0.620143</td>\n",
       "      <td>0.010631</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>BiGRU</td>\n",
       "      <td>random</td>\n",
       "      <td>16</td>\n",
       "      <td>0.488857</td>\n",
       "      <td>0.022944</td>\n",
       "      <td>0.610286</td>\n",
       "      <td>0.010978</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>BiLSTM</td>\n",
       "      <td>hierarchical_pretrained</td>\n",
       "      <td>2</td>\n",
       "      <td>0.538400</td>\n",
       "      <td>0.013703</td>\n",
       "      <td>0.651200</td>\n",
       "      <td>0.004425</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>BiLSTM</td>\n",
       "      <td>hierarchical_pretrained</td>\n",
       "      <td>4</td>\n",
       "      <td>0.532000</td>\n",
       "      <td>0.018058</td>\n",
       "      <td>0.645400</td>\n",
       "      <td>0.008264</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>BiLSTM</td>\n",
       "      <td>hierarchical_pretrained</td>\n",
       "      <td>8</td>\n",
       "      <td>0.527800</td>\n",
       "      <td>0.005649</td>\n",
       "      <td>0.643600</td>\n",
       "      <td>0.007057</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>BiLSTM</td>\n",
       "      <td>hierarchical_pretrained</td>\n",
       "      <td>16</td>\n",
       "      <td>0.523000</td>\n",
       "      <td>0.006392</td>\n",
       "      <td>0.637800</td>\n",
       "      <td>0.005784</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>BiLSTM</td>\n",
       "      <td>hierarchical_random</td>\n",
       "      <td>2</td>\n",
       "      <td>0.537800</td>\n",
       "      <td>0.015642</td>\n",
       "      <td>0.645600</td>\n",
       "      <td>0.008449</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>BiLSTM</td>\n",
       "      <td>hierarchical_random</td>\n",
       "      <td>4</td>\n",
       "      <td>0.538000</td>\n",
       "      <td>0.014320</td>\n",
       "      <td>0.646600</td>\n",
       "      <td>0.007583</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>BiLSTM</td>\n",
       "      <td>hierarchical_random</td>\n",
       "      <td>8</td>\n",
       "      <td>0.530800</td>\n",
       "      <td>0.013641</td>\n",
       "      <td>0.640200</td>\n",
       "      <td>0.009014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>BiLSTM</td>\n",
       "      <td>hierarchical_random</td>\n",
       "      <td>16</td>\n",
       "      <td>0.514200</td>\n",
       "      <td>0.030935</td>\n",
       "      <td>0.627200</td>\n",
       "      <td>0.015983</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>BiLSTM</td>\n",
       "      <td>pretrained</td>\n",
       "      <td>2</td>\n",
       "      <td>0.523200</td>\n",
       "      <td>0.041872</td>\n",
       "      <td>0.640000</td>\n",
       "      <td>0.026529</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>BiLSTM</td>\n",
       "      <td>pretrained</td>\n",
       "      <td>4</td>\n",
       "      <td>0.538600</td>\n",
       "      <td>0.028553</td>\n",
       "      <td>0.648800</td>\n",
       "      <td>0.012522</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>BiLSTM</td>\n",
       "      <td>pretrained</td>\n",
       "      <td>8</td>\n",
       "      <td>0.537000</td>\n",
       "      <td>0.027695</td>\n",
       "      <td>0.644000</td>\n",
       "      <td>0.011036</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>BiLSTM</td>\n",
       "      <td>pretrained</td>\n",
       "      <td>16</td>\n",
       "      <td>0.521600</td>\n",
       "      <td>0.032776</td>\n",
       "      <td>0.634800</td>\n",
       "      <td>0.016175</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>BiLSTM</td>\n",
       "      <td>random</td>\n",
       "      <td>2</td>\n",
       "      <td>0.536200</td>\n",
       "      <td>0.026939</td>\n",
       "      <td>0.642000</td>\n",
       "      <td>0.012166</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>BiLSTM</td>\n",
       "      <td>random</td>\n",
       "      <td>4</td>\n",
       "      <td>0.515200</td>\n",
       "      <td>0.035538</td>\n",
       "      <td>0.627800</td>\n",
       "      <td>0.021024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>BiLSTM</td>\n",
       "      <td>random</td>\n",
       "      <td>8</td>\n",
       "      <td>0.516400</td>\n",
       "      <td>0.009399</td>\n",
       "      <td>0.630000</td>\n",
       "      <td>0.007553</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>BiLSTM</td>\n",
       "      <td>random</td>\n",
       "      <td>16</td>\n",
       "      <td>0.505200</td>\n",
       "      <td>0.006594</td>\n",
       "      <td>0.617400</td>\n",
       "      <td>0.005013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>CLF</td>\n",
       "      <td>hierarchical_pretrained</td>\n",
       "      <td>2</td>\n",
       "      <td>0.575600</td>\n",
       "      <td>0.026465</td>\n",
       "      <td>0.663400</td>\n",
       "      <td>0.024749</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>CLF</td>\n",
       "      <td>hierarchical_pretrained</td>\n",
       "      <td>4</td>\n",
       "      <td>0.581800</td>\n",
       "      <td>0.008665</td>\n",
       "      <td>0.669000</td>\n",
       "      <td>0.003166</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>CLF</td>\n",
       "      <td>hierarchical_pretrained</td>\n",
       "      <td>8</td>\n",
       "      <td>0.553200</td>\n",
       "      <td>0.021603</td>\n",
       "      <td>0.649400</td>\n",
       "      <td>0.013562</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>CLF</td>\n",
       "      <td>hierarchical_pretrained</td>\n",
       "      <td>16</td>\n",
       "      <td>0.564000</td>\n",
       "      <td>0.021145</td>\n",
       "      <td>0.652600</td>\n",
       "      <td>0.010262</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>CLF</td>\n",
       "      <td>hierarchical_random</td>\n",
       "      <td>2</td>\n",
       "      <td>0.553600</td>\n",
       "      <td>0.039545</td>\n",
       "      <td>0.648400</td>\n",
       "      <td>0.021731</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>CLF</td>\n",
       "      <td>hierarchical_random</td>\n",
       "      <td>4</td>\n",
       "      <td>0.559600</td>\n",
       "      <td>0.024499</td>\n",
       "      <td>0.651200</td>\n",
       "      <td>0.012946</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>CLF</td>\n",
       "      <td>hierarchical_random</td>\n",
       "      <td>8</td>\n",
       "      <td>0.560400</td>\n",
       "      <td>0.020936</td>\n",
       "      <td>0.649600</td>\n",
       "      <td>0.012802</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>CLF</td>\n",
       "      <td>hierarchical_random</td>\n",
       "      <td>16</td>\n",
       "      <td>0.530800</td>\n",
       "      <td>0.012766</td>\n",
       "      <td>0.631600</td>\n",
       "      <td>0.009440</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>CLF</td>\n",
       "      <td>pretrained</td>\n",
       "      <td>2</td>\n",
       "      <td>0.568400</td>\n",
       "      <td>0.019506</td>\n",
       "      <td>0.667800</td>\n",
       "      <td>0.011154</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>CLF</td>\n",
       "      <td>pretrained</td>\n",
       "      <td>4</td>\n",
       "      <td>0.555000</td>\n",
       "      <td>0.013799</td>\n",
       "      <td>0.653200</td>\n",
       "      <td>0.011154</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>CLF</td>\n",
       "      <td>pretrained</td>\n",
       "      <td>8</td>\n",
       "      <td>0.559200</td>\n",
       "      <td>0.025163</td>\n",
       "      <td>0.653800</td>\n",
       "      <td>0.011561</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>CLF</td>\n",
       "      <td>pretrained</td>\n",
       "      <td>16</td>\n",
       "      <td>0.558800</td>\n",
       "      <td>0.020316</td>\n",
       "      <td>0.652000</td>\n",
       "      <td>0.009250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>CLF</td>\n",
       "      <td>random</td>\n",
       "      <td>2</td>\n",
       "      <td>0.579400</td>\n",
       "      <td>0.015323</td>\n",
       "      <td>0.661800</td>\n",
       "      <td>0.007573</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>CLF</td>\n",
       "      <td>random</td>\n",
       "      <td>4</td>\n",
       "      <td>0.543000</td>\n",
       "      <td>0.041163</td>\n",
       "      <td>0.643200</td>\n",
       "      <td>0.022716</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>CLF</td>\n",
       "      <td>random</td>\n",
       "      <td>8</td>\n",
       "      <td>0.538000</td>\n",
       "      <td>0.041443</td>\n",
       "      <td>0.635400</td>\n",
       "      <td>0.026275</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>CLF</td>\n",
       "      <td>random</td>\n",
       "      <td>16</td>\n",
       "      <td>0.562400</td>\n",
       "      <td>0.020954</td>\n",
       "      <td>0.647200</td>\n",
       "      <td>0.011085</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>CNN</td>\n",
       "      <td>hierarchical_pretrained</td>\n",
       "      <td>2</td>\n",
       "      <td>0.523000</td>\n",
       "      <td>0.007404</td>\n",
       "      <td>0.635087</td>\n",
       "      <td>0.004626</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>CNN</td>\n",
       "      <td>hierarchical_pretrained</td>\n",
       "      <td>4</td>\n",
       "      <td>0.513652</td>\n",
       "      <td>0.010139</td>\n",
       "      <td>0.628130</td>\n",
       "      <td>0.006486</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>CNN</td>\n",
       "      <td>hierarchical_pretrained</td>\n",
       "      <td>6</td>\n",
       "      <td>0.502409</td>\n",
       "      <td>0.011084</td>\n",
       "      <td>0.621500</td>\n",
       "      <td>0.007847</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>CNN</td>\n",
       "      <td>hierarchical_pretrained</td>\n",
       "      <td>10</td>\n",
       "      <td>0.503000</td>\n",
       "      <td>0.010816</td>\n",
       "      <td>0.621500</td>\n",
       "      <td>0.006834</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>CNN</td>\n",
       "      <td>hierarchical_random</td>\n",
       "      <td>2</td>\n",
       "      <td>0.535400</td>\n",
       "      <td>0.005638</td>\n",
       "      <td>0.641560</td>\n",
       "      <td>0.002984</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>CNN</td>\n",
       "      <td>hierarchical_random</td>\n",
       "      <td>4</td>\n",
       "      <td>0.529120</td>\n",
       "      <td>0.004128</td>\n",
       "      <td>0.639280</td>\n",
       "      <td>0.002819</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>CNN</td>\n",
       "      <td>hierarchical_random</td>\n",
       "      <td>6</td>\n",
       "      <td>0.508440</td>\n",
       "      <td>0.004511</td>\n",
       "      <td>0.629680</td>\n",
       "      <td>0.002758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>CNN</td>\n",
       "      <td>hierarchical_random</td>\n",
       "      <td>10</td>\n",
       "      <td>0.513360</td>\n",
       "      <td>0.003502</td>\n",
       "      <td>0.630720</td>\n",
       "      <td>0.001102</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>CNN</td>\n",
       "      <td>pretrained</td>\n",
       "      <td>2</td>\n",
       "      <td>0.533160</td>\n",
       "      <td>0.003380</td>\n",
       "      <td>0.639720</td>\n",
       "      <td>0.002055</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>CNN</td>\n",
       "      <td>pretrained</td>\n",
       "      <td>4</td>\n",
       "      <td>0.515000</td>\n",
       "      <td>0.007733</td>\n",
       "      <td>0.629760</td>\n",
       "      <td>0.003716</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>CNN</td>\n",
       "      <td>pretrained</td>\n",
       "      <td>6</td>\n",
       "      <td>0.514840</td>\n",
       "      <td>0.005814</td>\n",
       "      <td>0.626280</td>\n",
       "      <td>0.002956</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>CNN</td>\n",
       "      <td>pretrained</td>\n",
       "      <td>10</td>\n",
       "      <td>0.501480</td>\n",
       "      <td>0.003694</td>\n",
       "      <td>0.617600</td>\n",
       "      <td>0.003239</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>CNN</td>\n",
       "      <td>random</td>\n",
       "      <td>2</td>\n",
       "      <td>0.535200</td>\n",
       "      <td>0.008454</td>\n",
       "      <td>0.643480</td>\n",
       "      <td>0.005018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>CNN</td>\n",
       "      <td>random</td>\n",
       "      <td>4</td>\n",
       "      <td>0.526040</td>\n",
       "      <td>0.011867</td>\n",
       "      <td>0.636720</td>\n",
       "      <td>0.006746</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>CNN</td>\n",
       "      <td>random</td>\n",
       "      <td>6</td>\n",
       "      <td>0.519720</td>\n",
       "      <td>0.011065</td>\n",
       "      <td>0.636560</td>\n",
       "      <td>0.005690</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>CNN</td>\n",
       "      <td>random</td>\n",
       "      <td>10</td>\n",
       "      <td>0.503160</td>\n",
       "      <td>0.009848</td>\n",
       "      <td>0.625600</td>\n",
       "      <td>0.004868</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     model               att_module  num_heads  f1_macro_sk_mean  \\\n",
       "0    BiGRU  hierarchical_pretrained          2          0.543200   \n",
       "1    BiGRU  hierarchical_pretrained          4          0.555600   \n",
       "2    BiGRU  hierarchical_pretrained          8          0.541900   \n",
       "3    BiGRU  hierarchical_pretrained         16          0.529000   \n",
       "4    BiGRU      hierarchical_random          2          0.552600   \n",
       "5    BiGRU      hierarchical_random          4          0.549200   \n",
       "6    BiGRU      hierarchical_random          8          0.546000   \n",
       "7    BiGRU      hierarchical_random         16          0.533200   \n",
       "8    BiGRU               pretrained          2          0.525800   \n",
       "9    BiGRU               pretrained          4          0.537400   \n",
       "10   BiGRU               pretrained          8          0.541800   \n",
       "11   BiGRU               pretrained         16          0.530600   \n",
       "12   BiGRU                   random          2          0.532250   \n",
       "13   BiGRU                   random          4          0.523286   \n",
       "14   BiGRU                   random          8          0.501000   \n",
       "15   BiGRU                   random         16          0.488857   \n",
       "16  BiLSTM  hierarchical_pretrained          2          0.538400   \n",
       "17  BiLSTM  hierarchical_pretrained          4          0.532000   \n",
       "18  BiLSTM  hierarchical_pretrained          8          0.527800   \n",
       "19  BiLSTM  hierarchical_pretrained         16          0.523000   \n",
       "20  BiLSTM      hierarchical_random          2          0.537800   \n",
       "21  BiLSTM      hierarchical_random          4          0.538000   \n",
       "22  BiLSTM      hierarchical_random          8          0.530800   \n",
       "23  BiLSTM      hierarchical_random         16          0.514200   \n",
       "24  BiLSTM               pretrained          2          0.523200   \n",
       "25  BiLSTM               pretrained          4          0.538600   \n",
       "26  BiLSTM               pretrained          8          0.537000   \n",
       "27  BiLSTM               pretrained         16          0.521600   \n",
       "28  BiLSTM                   random          2          0.536200   \n",
       "29  BiLSTM                   random          4          0.515200   \n",
       "30  BiLSTM                   random          8          0.516400   \n",
       "31  BiLSTM                   random         16          0.505200   \n",
       "32     CLF  hierarchical_pretrained          2          0.575600   \n",
       "33     CLF  hierarchical_pretrained          4          0.581800   \n",
       "34     CLF  hierarchical_pretrained          8          0.553200   \n",
       "35     CLF  hierarchical_pretrained         16          0.564000   \n",
       "36     CLF      hierarchical_random          2          0.553600   \n",
       "37     CLF      hierarchical_random          4          0.559600   \n",
       "38     CLF      hierarchical_random          8          0.560400   \n",
       "39     CLF      hierarchical_random         16          0.530800   \n",
       "40     CLF               pretrained          2          0.568400   \n",
       "41     CLF               pretrained          4          0.555000   \n",
       "42     CLF               pretrained          8          0.559200   \n",
       "43     CLF               pretrained         16          0.558800   \n",
       "44     CLF                   random          2          0.579400   \n",
       "45     CLF                   random          4          0.543000   \n",
       "46     CLF                   random          8          0.538000   \n",
       "47     CLF                   random         16          0.562400   \n",
       "48     CNN  hierarchical_pretrained          2          0.523000   \n",
       "49     CNN  hierarchical_pretrained          4          0.513652   \n",
       "50     CNN  hierarchical_pretrained          6          0.502409   \n",
       "51     CNN  hierarchical_pretrained         10          0.503000   \n",
       "52     CNN      hierarchical_random          2          0.535400   \n",
       "53     CNN      hierarchical_random          4          0.529120   \n",
       "54     CNN      hierarchical_random          6          0.508440   \n",
       "55     CNN      hierarchical_random         10          0.513360   \n",
       "56     CNN               pretrained          2          0.533160   \n",
       "57     CNN               pretrained          4          0.515000   \n",
       "58     CNN               pretrained          6          0.514840   \n",
       "59     CNN               pretrained         10          0.501480   \n",
       "60     CNN                   random          2          0.535200   \n",
       "61     CNN                   random          4          0.526040   \n",
       "62     CNN                   random          6          0.519720   \n",
       "63     CNN                   random         10          0.503160   \n",
       "\n",
       "    f1_macro_sk_ci_95  f1_micro_sk_mean  f1_micro_sk_ci_95  \n",
       "0            0.008183          0.644800           0.005508  \n",
       "1            0.008684          0.652400           0.004614  \n",
       "2            0.009102          0.645600           0.006567  \n",
       "3            0.007675          0.639400           0.004924  \n",
       "4            0.018367          0.650200           0.008255  \n",
       "5            0.024290          0.646200           0.014780  \n",
       "6            0.010931          0.644000           0.002323  \n",
       "7            0.016966          0.634600           0.008123  \n",
       "8            0.018320          0.635400           0.012342  \n",
       "9            0.033715          0.643200           0.017808  \n",
       "10           0.027687          0.644800           0.011955  \n",
       "11           0.024562          0.639000           0.015853  \n",
       "12           0.015986          0.636625           0.006303  \n",
       "13           0.017226          0.634143           0.008088  \n",
       "14           0.017717          0.620143           0.010631  \n",
       "15           0.022944          0.610286           0.010978  \n",
       "16           0.013703          0.651200           0.004425  \n",
       "17           0.018058          0.645400           0.008264  \n",
       "18           0.005649          0.643600           0.007057  \n",
       "19           0.006392          0.637800           0.005784  \n",
       "20           0.015642          0.645600           0.008449  \n",
       "21           0.014320          0.646600           0.007583  \n",
       "22           0.013641          0.640200           0.009014  \n",
       "23           0.030935          0.627200           0.015983  \n",
       "24           0.041872          0.640000           0.026529  \n",
       "25           0.028553          0.648800           0.012522  \n",
       "26           0.027695          0.644000           0.011036  \n",
       "27           0.032776          0.634800           0.016175  \n",
       "28           0.026939          0.642000           0.012166  \n",
       "29           0.035538          0.627800           0.021024  \n",
       "30           0.009399          0.630000           0.007553  \n",
       "31           0.006594          0.617400           0.005013  \n",
       "32           0.026465          0.663400           0.024749  \n",
       "33           0.008665          0.669000           0.003166  \n",
       "34           0.021603          0.649400           0.013562  \n",
       "35           0.021145          0.652600           0.010262  \n",
       "36           0.039545          0.648400           0.021731  \n",
       "37           0.024499          0.651200           0.012946  \n",
       "38           0.020936          0.649600           0.012802  \n",
       "39           0.012766          0.631600           0.009440  \n",
       "40           0.019506          0.667800           0.011154  \n",
       "41           0.013799          0.653200           0.011154  \n",
       "42           0.025163          0.653800           0.011561  \n",
       "43           0.020316          0.652000           0.009250  \n",
       "44           0.015323          0.661800           0.007573  \n",
       "45           0.041163          0.643200           0.022716  \n",
       "46           0.041443          0.635400           0.026275  \n",
       "47           0.020954          0.647200           0.011085  \n",
       "48           0.007404          0.635087           0.004626  \n",
       "49           0.010139          0.628130           0.006486  \n",
       "50           0.011084          0.621500           0.007847  \n",
       "51           0.010816          0.621500           0.006834  \n",
       "52           0.005638          0.641560           0.002984  \n",
       "53           0.004128          0.639280           0.002819  \n",
       "54           0.004511          0.629680           0.002758  \n",
       "55           0.003502          0.630720           0.001102  \n",
       "56           0.003380          0.639720           0.002055  \n",
       "57           0.007733          0.629760           0.003716  \n",
       "58           0.005814          0.626280           0.002956  \n",
       "59           0.003694          0.617600           0.003239  \n",
       "60           0.008454          0.643480           0.005018  \n",
       "61           0.011867          0.636720           0.006746  \n",
       "62           0.011065          0.636560           0.005690  \n",
       "63           0.009848          0.625600           0.004868  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load multihead results\n",
    "# We have two files that contain results for our experiments with multilabel attention \n",
    "df_50_mh = pd.read_excel(os.path.join(path_results, 'results_section_C', 'Mimic50_scores_multihead.xlsx'))\n",
    "\n",
    "# Drop columns that are not necessary\n",
    "df_50_mh = df_50_mh.drop(['epoch', 'doc_max_len', 'batch_size', 'patience', 'embedding_scaling', 'word_embedding_dim',\n",
    "                   'kernel_sizes', 'hidden_dim', 'dropout_p', 'scale', 'multihead'], axis=1)\n",
    "\n",
    "# Group results\n",
    "df_50_mh_grp = df_50_mh.groupby(['Model', 'att_module', 'num_heads'])[['f1_macro_sk', 'f1_micro_sk']].agg(['mean', ci_95]).reset_index()\n",
    "df_50_mh_grp\n",
    "\n",
    "# Remove multi-level indexed columns \n",
    "df_50_mh_grp.columns = df_50_mh_grp.columns.map('{0[0]}_{0[1]}'.format)\n",
    "df_50_mh_grp = df_50_mh_grp.fillna(0)\n",
    "\n",
    "df_50_mh_grp = df_50_mh_grp.rename(columns={'Model_': 'model', 'att_module_': 'att_module', 'num_heads_': 'num_heads'})\n",
    "\n",
    "df_50_mh_grp\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b0b6c55",
   "metadata": {},
   "source": [
    "# Compute Signficance between Single- and Multi-Head Attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "be13284e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CNN and random\n",
      "Number of Heads: 2\n",
      "Single-Head Macro UB: 0.54365442988236\n",
      "Single-Head Macro LB: 0.52674557011764\n",
      "Single-Head Micro UB: 0.6484976086487995\n",
      "Single-Head Micro LB: 0.6384623913512004\n",
      "Number of Heads: 4\n",
      "Single-Head Macro UB: 0.5379066569510764\n",
      "Single-Head Macro LB: 0.5141733430489235\n",
      "Single-Head Micro UB: 0.6434664757938631\n",
      "Single-Head Micro LB: 0.6299735242061371\n",
      "Number of Heads: 6\n",
      "Single-Head Macro UB: 0.5307848320483287\n",
      "Single-Head Macro LB: 0.5086551679516712\n",
      "Single-Head Micro UB: 0.6422498754983202\n",
      "Single-Head Micro LB: 0.6308701245016798\n",
      "Number of Heads: 10\n",
      "Single-Head Macro UB: 0.5130075432935914\n",
      "Single-Head Macro LB: 0.49331245670640866\n",
      "Single-Head Micro UB: 0.6304680596299141\n",
      "Single-Head Micro LB: 0.6207319403700859\n",
      "CNN and pretrained\n",
      "Number of Heads: 2\n",
      "Single-Head Macro UB: 0.5365401760840665\n",
      "Single-Head Macro LB: 0.5297798239159337\n",
      "Single-Head Micro UB: 0.641775350077376\n",
      "Single-Head Micro LB: 0.6376646499226242\n",
      "Number of Heads: 4\n",
      "Single-Head Macro UB: 0.5227334254317586\n",
      "Single-Head Macro LB: 0.5072665745682414\n",
      "Single-Head Micro UB: 0.6334755524572133\n",
      "Single-Head Micro LB: 0.6260444475427867\n",
      "Number of Heads: 6\n",
      "Single-Head Macro UB: 0.5206540429105021\n",
      "Single-Head Macro LB: 0.5090259570894978\n",
      "Single-Head Micro UB: 0.62923630205656\n",
      "Single-Head Micro LB: 0.6233236979434399\n",
      "Number of Heads: 10\n",
      "Single-Head Macro UB: 0.5051741670330077\n",
      "Single-Head Macro LB: 0.4977858329669924\n",
      "Single-Head Micro UB: 0.6208392908197721\n",
      "Single-Head Micro LB: 0.6143607091802278\n",
      "CNN and hierarchical_random\n",
      "Number of Heads: 2\n",
      "Single-Head Macro UB: 0.5410383855294324\n",
      "Single-Head Macro LB: 0.5297616144705678\n",
      "Single-Head Micro UB: 0.6445439338822873\n",
      "Single-Head Micro LB: 0.6385760661177128\n",
      "Number of Heads: 4\n",
      "Single-Head Macro UB: 0.5332483474595192\n",
      "Single-Head Macro LB: 0.5249916525404809\n",
      "Single-Head Micro UB: 0.6420986135052633\n",
      "Single-Head Micro LB: 0.6364613864947368\n",
      "Number of Heads: 6\n",
      "Single-Head Macro UB: 0.5129508972891385\n",
      "Single-Head Macro LB: 0.5039291027108616\n",
      "Single-Head Micro UB: 0.6324380151731065\n",
      "Single-Head Micro LB: 0.6269219848268935\n",
      "Number of Heads: 10\n",
      "Single-Head Macro UB: 0.5168623087634358\n",
      "Single-Head Macro LB: 0.5098576912365643\n",
      "Single-Head Micro UB: 0.6318219491826766\n",
      "Single-Head Micro LB: 0.6296180508173235\n",
      "CNN and hierarchical_pretrained\n",
      "Number of Heads: 2\n",
      "Single-Head Macro UB: 0.5304043471216147\n",
      "Single-Head Macro LB: 0.5155956528783854\n",
      "Single-Head Micro UB: 0.6397131072394483\n",
      "Single-Head Micro LB: 0.6304608058040299\n",
      "Number of Heads: 4\n",
      "Single-Head Macro UB: 0.5237916088448925\n",
      "Single-Head Macro LB: 0.5035127389811945\n",
      "Single-Head Micro UB: 0.6346160095487758\n",
      "Single-Head Micro LB: 0.6216448600164415\n",
      "Number of Heads: 6\n",
      "Single-Head Macro UB: 0.5134927597543065\n",
      "Single-Head Macro LB: 0.4913254220638753\n",
      "Single-Head Micro UB: 0.6293467919997824\n",
      "Single-Head Micro LB: 0.6136532080002177\n",
      "Number of Heads: 10\n",
      "Single-Head Macro UB: 0.513816380895474\n",
      "Single-Head Macro LB: 0.492183619104526\n",
      "Single-Head Micro UB: 0.6283342399960665\n",
      "Single-Head Micro LB: 0.6146657600039336\n",
      "BiGRU and random\n",
      "Number of Heads: 2\n",
      "Single-Head Macro UB: 0.548236216589919\n",
      "Single-Head Macro LB: 0.5162637834100811\n",
      "Single-Head Micro UB: 0.6429279150182226\n",
      "Single-Head Micro LB: 0.6303220849817774\n",
      "Number of Heads: 4\n",
      "Single-Head Macro UB: 0.5405113173201099\n",
      "Single-Head Macro LB: 0.5060601112513188\n",
      "Single-Head Micro UB: 0.6422306948325701\n",
      "Single-Head Micro LB: 0.6260550194531441\n",
      "Number of Heads: 8\n",
      "Single-Head Macro UB: 0.5187174957019602\n",
      "Single-Head Macro LB: 0.48328250429803976\n",
      "Single-Head Micro UB: 0.6307742740776949\n",
      "Single-Head Micro LB: 0.6095114402080195\n",
      "Number of Heads: 16\n",
      "Single-Head Macro UB: 0.5118014491959373\n",
      "Single-Head Macro LB: 0.4659128365183484\n",
      "Single-Head Micro UB: 0.6212639395818179\n",
      "Single-Head Micro LB: 0.5993074889896107\n",
      "BiGRU and pretrained\n",
      "Number of Heads: 2\n",
      "Single-Head Macro UB: 0.54412033047632\n",
      "Single-Head Macro LB: 0.5074796695236801\n",
      "Single-Head Micro UB: 0.6477419152914858\n",
      "Single-Head Micro LB: 0.6230580847085141\n",
      "Number of Heads: 4\n",
      "Single-Head Macro UB: 0.5711152361533209\n",
      "Single-Head Macro LB: 0.5036847638466793\n",
      "Single-Head Micro UB: 0.6610082496317958\n",
      "Single-Head Micro LB: 0.6253917503682042\n",
      "Number of Heads: 8\n",
      "Single-Head Macro UB: 0.5694866014465709\n",
      "Single-Head Macro LB: 0.5141133985534292\n",
      "Single-Head Micro UB: 0.6567548451770469\n",
      "Single-Head Micro LB: 0.6328451548229532\n",
      "Number of Heads: 16\n",
      "Single-Head Macro UB: 0.5551617333928116\n",
      "Single-Head Macro LB: 0.5060382666071883\n",
      "Single-Head Micro UB: 0.6548525047220609\n",
      "Single-Head Micro LB: 0.6231474952779391\n",
      "BiGRU and hierarchical_random\n",
      "Number of Heads: 2\n",
      "Single-Head Macro UB: 0.5709665568682444\n",
      "Single-Head Macro LB: 0.5342334431317556\n",
      "Single-Head Micro UB: 0.6584549647614054\n",
      "Single-Head Micro LB: 0.6419450352385948\n",
      "Number of Heads: 4\n",
      "Single-Head Macro UB: 0.5734903246930422\n",
      "Single-Head Macro LB: 0.5249096753069579\n",
      "Single-Head Micro UB: 0.660980496200889\n",
      "Single-Head Micro LB: 0.631419503799111\n",
      "Number of Heads: 8\n",
      "Single-Head Macro UB: 0.5569308753100446\n",
      "Single-Head Macro LB: 0.5350691246899555\n",
      "Single-Head Micro UB: 0.6463229406353852\n",
      "Single-Head Micro LB: 0.6416770593646148\n",
      "Number of Heads: 16\n",
      "Single-Head Macro UB: 0.5501658744173145\n",
      "Single-Head Macro LB: 0.5162341255826858\n",
      "Single-Head Micro UB: 0.6427231780685785\n",
      "Single-Head Micro LB: 0.6264768219314216\n",
      "BiGRU and hierarchical_pretrained\n",
      "Number of Heads: 2\n",
      "Single-Head Macro UB: 0.5513827713874132\n",
      "Single-Head Macro LB: 0.5350172286125868\n",
      "Single-Head Micro UB: 0.6503081965625407\n",
      "Single-Head Micro LB: 0.6392918034374594\n",
      "Number of Heads: 4\n",
      "Single-Head Macro UB: 0.5642843791503201\n",
      "Single-Head Macro LB: 0.5469156208496798\n",
      "Single-Head Micro UB: 0.657013913406252\n",
      "Single-Head Micro LB: 0.6477860865937479\n",
      "Number of Heads: 8\n",
      "Single-Head Macro UB: 0.5510015716235429\n",
      "Single-Head Macro LB: 0.5327984283764572\n",
      "Single-Head Micro UB: 0.652166753006157\n",
      "Single-Head Micro LB: 0.6390332469938431\n",
      "Number of Heads: 16\n",
      "Single-Head Macro UB: 0.5366750532462737\n",
      "Single-Head Macro LB: 0.5213249467537263\n",
      "Single-Head Micro UB: 0.6443239101268314\n",
      "Single-Head Micro LB: 0.6344760898731685\n",
      "BiLSTM and random\n",
      "Number of Heads: 2\n",
      "Single-Head Macro UB: 0.5631386723563676\n",
      "Single-Head Macro LB: 0.5092613276436324\n",
      "Single-Head Micro UB: 0.6541657729103332\n",
      "Single-Head Micro LB: 0.6298342270896669\n",
      "Number of Heads: 4\n",
      "Single-Head Macro UB: 0.5507384973465318\n",
      "Single-Head Macro LB: 0.4796615026534682\n",
      "Single-Head Micro UB: 0.6488241252656947\n",
      "Single-Head Micro LB: 0.6067758747343054\n",
      "Number of Heads: 8\n",
      "Single-Head Macro UB: 0.5257989945982613\n",
      "Single-Head Macro LB: 0.5070010054017386\n",
      "Single-Head Micro UB: 0.6375527472434942\n",
      "Single-Head Micro LB: 0.6224472527565058\n",
      "Number of Heads: 16\n",
      "Single-Head Macro UB: 0.5117936917930002\n",
      "Single-Head Macro LB: 0.4986063082069998\n",
      "Single-Head Micro UB: 0.6224130021540286\n",
      "Single-Head Micro LB: 0.6123869978459713\n",
      "BiLSTM and pretrained\n",
      "Number of Heads: 2\n",
      "Single-Head Macro UB: 0.5650718851940045\n",
      "Single-Head Macro LB: 0.48132811480599547\n",
      "Single-Head Micro UB: 0.666529219921527\n",
      "Single-Head Micro LB: 0.613470780078473\n",
      "Number of Heads: 4\n",
      "Single-Head Macro UB: 0.5671528729092086\n",
      "Single-Head Macro LB: 0.5100471270907914\n",
      "Single-Head Micro UB: 0.6613217366434164\n",
      "Single-Head Micro LB: 0.6362782633565837\n",
      "Number of Heads: 8\n",
      "Single-Head Macro UB: 0.5646949529428485\n",
      "Single-Head Macro LB: 0.5093050470571515\n",
      "Single-Head Micro UB: 0.6550361510170165\n",
      "Single-Head Micro LB: 0.6329638489829835\n",
      "Number of Heads: 16\n",
      "Single-Head Macro UB: 0.5543761667184338\n",
      "Single-Head Macro LB: 0.4888238332815663\n",
      "Single-Head Micro UB: 0.6509750268472322\n",
      "Single-Head Micro LB: 0.6186249731527679\n",
      "BiLSTM and hierarchical_random\n",
      "Number of Heads: 2\n",
      "Single-Head Macro UB: 0.55344200975514\n",
      "Single-Head Macro LB: 0.5221579902448601\n",
      "Single-Head Micro UB: 0.6540487913413315\n",
      "Single-Head Micro LB: 0.6371512086586686\n",
      "Number of Heads: 4\n",
      "Single-Head Macro UB: 0.5523195677808342\n",
      "Single-Head Macro LB: 0.5236804322191658\n",
      "Single-Head Micro UB: 0.6541833046733888\n",
      "Single-Head Micro LB: 0.6390166953266113\n",
      "Number of Heads: 8\n",
      "Single-Head Macro UB: 0.5444413616905112\n",
      "Single-Head Macro LB: 0.5171586383094887\n",
      "Single-Head Micro UB: 0.649213830696754\n",
      "Single-Head Micro LB: 0.631186169303246\n",
      "Number of Heads: 16\n",
      "Single-Head Macro UB: 0.5451346325497658\n",
      "Single-Head Macro LB: 0.4832653674502342\n",
      "Single-Head Micro UB: 0.6431832592286724\n",
      "Single-Head Micro LB: 0.6112167407713276\n",
      "BiLSTM and hierarchical_pretrained\n",
      "Number of Heads: 2\n",
      "Single-Head Macro UB: 0.5521033810136122\n",
      "Single-Head Macro LB: 0.5246966189863878\n",
      "Single-Head Micro UB: 0.6556249253612156\n",
      "Single-Head Micro LB: 0.6467750746387844\n",
      "Number of Heads: 4\n",
      "Single-Head Macro UB: 0.5500575686613143\n",
      "Single-Head Macro LB: 0.5139424313386858\n",
      "Single-Head Micro UB: 0.6536642976810185\n",
      "Single-Head Micro LB: 0.6371357023189816\n",
      "Number of Heads: 8\n",
      "Single-Head Macro UB: 0.5334492300650454\n",
      "Single-Head Macro LB: 0.5221507699349547\n",
      "Single-Head Micro UB: 0.6506567600460311\n",
      "Single-Head Micro LB: 0.6365432399539688\n",
      "Number of Heads: 16\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Single-Head Macro UB: 0.5293918566424426\n",
      "Single-Head Macro LB: 0.5166081433575574\n",
      "Single-Head Micro UB: 0.6435840755365269\n",
      "Single-Head Micro LB: 0.6320159244634732\n",
      "CLF and random\n",
      "Number of Heads: 2\n",
      "Single-Head Macro UB: 0.5947233612657113\n",
      "Single-Head Macro LB: 0.5640766387342885\n",
      "Single-Head Micro UB: 0.669373132563279\n",
      "Single-Head Micro LB: 0.6542268674367211\n",
      "Number of Heads: 4\n",
      "Single-Head Macro UB: 0.5841626129320583\n",
      "Single-Head Macro LB: 0.5018373870679416\n",
      "Single-Head Micro UB: 0.665916004455901\n",
      "Single-Head Micro LB: 0.6204839955440989\n",
      "Number of Heads: 8\n",
      "Single-Head Macro UB: 0.5794425704519036\n",
      "Single-Head Macro LB: 0.49655742954809645\n",
      "Single-Head Micro UB: 0.661675206243342\n",
      "Single-Head Micro LB: 0.609124793756658\n",
      "Number of Heads: 16\n",
      "Single-Head Macro UB: 0.5833543445893015\n",
      "Single-Head Macro LB: 0.5414456554106986\n",
      "Single-Head Micro UB: 0.658284937523933\n",
      "Single-Head Micro LB: 0.636115062476067\n",
      "CLF and pretrained\n",
      "Number of Heads: 2\n",
      "Single-Head Macro UB: 0.5879063793862072\n",
      "Single-Head Macro LB: 0.5488936206137929\n",
      "Single-Head Micro UB: 0.6789542623868159\n",
      "Single-Head Micro LB: 0.6566457376131842\n",
      "Number of Heads: 4\n",
      "Single-Head Macro UB: 0.5687986807821532\n",
      "Single-Head Macro LB: 0.5412013192178466\n",
      "Single-Head Micro UB: 0.6643542623868158\n",
      "Single-Head Micro LB: 0.6420457376131842\n",
      "Number of Heads: 8\n",
      "Single-Head Macro UB: 0.5843632330843554\n",
      "Single-Head Macro LB: 0.5340367669156446\n",
      "Single-Head Micro UB: 0.6653614854711905\n",
      "Single-Head Micro LB: 0.6422385145288096\n",
      "Number of Heads: 16\n",
      "Single-Head Macro UB: 0.5791155355081609\n",
      "Single-Head Macro LB: 0.5384844644918391\n",
      "Single-Head Micro UB: 0.6612501884513865\n",
      "Single-Head Micro LB: 0.6427498115486135\n",
      "CLF and hierarchical_random\n",
      "Number of Heads: 2\n",
      "Single-Head Macro UB: 0.5931446104553172\n",
      "Single-Head Macro LB: 0.5140553895446828\n",
      "Single-Head Micro UB: 0.6701308937018833\n",
      "Single-Head Micro LB: 0.6266691062981167\n",
      "Number of Heads: 4\n",
      "Single-Head Macro UB: 0.5840988834090594\n",
      "Single-Head Macro LB: 0.5351011165909406\n",
      "Single-Head Micro UB: 0.6641455009543132\n",
      "Single-Head Micro LB: 0.6382544990456868\n",
      "Number of Heads: 8\n",
      "Single-Head Macro UB: 0.5813359425970022\n",
      "Single-Head Macro LB: 0.5394640574029979\n",
      "Single-Head Micro UB: 0.662401790663633\n",
      "Single-Head Micro LB: 0.6367982093363671\n",
      "Number of Heads: 16\n",
      "Single-Head Macro UB: 0.5435656103067897\n",
      "Single-Head Macro LB: 0.5180343896932101\n",
      "Single-Head Micro UB: 0.6410399133576724\n",
      "Single-Head Micro LB: 0.6221600866423275\n",
      "CLF and hierarchical_pretrained\n",
      "Number of Heads: 2\n",
      "Single-Head Macro UB: 0.602065216885168\n",
      "Single-Head Macro LB: 0.549134783114832\n",
      "Single-Head Micro UB: 0.6881493257315461\n",
      "Single-Head Micro LB: 0.6386506742684539\n",
      "Number of Heads: 4\n",
      "Single-Head Macro UB: 0.5904650000514715\n",
      "Single-Head Macro LB: 0.5731349999485285\n",
      "Single-Head Micro UB: 0.6721656344780834\n",
      "Single-Head Micro LB: 0.6658343655219167\n",
      "Number of Heads: 8\n",
      "Single-Head Macro UB: 0.5748028126626739\n",
      "Single-Head Macro LB: 0.5315971873373262\n",
      "Single-Head Micro UB: 0.6629620178252773\n",
      "Single-Head Micro LB: 0.6358379821747226\n",
      "Number of Heads: 16\n",
      "Single-Head Macro UB: 0.5851447759620729\n",
      "Single-Head Macro LB: 0.5428552240379272\n",
      "Single-Head Micro UB: 0.662861584857464\n",
      "Single-Head Micro LB: 0.6423384151425359\n"
     ]
    }
   ],
   "source": [
    "# Comparison between single- and multihead performances\n",
    "models = ['CNN', 'BiGRU', 'BiLSTM', 'CLF']\n",
    "atts = ['random', 'pretrained', 'hierarchical_random', 'hierarchical_pretrained']\n",
    "\n",
    "model_col = []\n",
    "att_col = []\n",
    "nh_col = []\n",
    "macro_sig = []\n",
    "micro_sig = []\n",
    "\n",
    "macro_larger = []\n",
    "micro_larger = []\n",
    "\n",
    "\n",
    "# Remove baseline and target module\n",
    "df50_grp = df_50_grp[~df_50_grp['att_module'].isin(['baseline', 'target'])].copy()\n",
    "df50_mh_grp = df_50_mh_grp.copy()\n",
    "\n",
    "\n",
    "for model in models:\n",
    "    for att in atts:\n",
    "        print(f'{model} and {att}')\n",
    "        sh_macro = df50_grp[df50_grp['model']==model][df50_grp['att_module']==att]['f1_macro_sk_mean'].reset_index(drop=True)[0]\n",
    "        sh_macro_95 = df50_grp[df50_grp['model']==model][df50_grp['att_module']==att]['f1_macro_sk_ci_95'].reset_index(drop=True)[0]\n",
    "\n",
    "        sh_micro = df50_grp[df50_grp['model']==model][df50_grp['att_module']==att]['f1_micro_sk_mean'].reset_index(drop=True)[0]\n",
    "        sh_micro_95 = df50_grp[df50_grp['model']==model][df50_grp['att_module']==att]['f1_micro_sk_ci_95'].reset_index(drop=True)[0]\n",
    "\n",
    "        sh_macro_ub = sh_macro + sh_macro_95\n",
    "        sh_macro_lb = sh_macro - sh_macro_95\n",
    "        \n",
    "        sh_micro_ub = sh_micro + sh_micro_95\n",
    "        sh_micro_lb = sh_micro - sh_micro_95\n",
    "    \n",
    "        if model == 'CNN':\n",
    "            nh = [2, 4, 6, 10]\n",
    "        else:\n",
    "            nh = [2, 4, 8, 16]\n",
    "        for n in nh:\n",
    "            print(f'Number of Heads: {n}')\n",
    "            mh_macro = df50_mh_grp[df50_mh_grp['model']==model][df50_mh_grp['att_module']==att][df50_mh_grp['num_heads']==n]['f1_macro_sk_mean'].reset_index(drop=True)[0]\n",
    "            mh_macro_95 = df50_mh_grp[df50_mh_grp['model']==model][df50_mh_grp['att_module']==att][df50_mh_grp['num_heads']==n]['f1_macro_sk_ci_95'].reset_index(drop=True)[0]\n",
    "            mh_micro = df50_mh_grp[df50_mh_grp['model']==model][df50_mh_grp['att_module']==att][df50_mh_grp['num_heads']==n]['f1_micro_sk_mean'].reset_index(drop=True)[0]\n",
    "            mh_micro_95 = df50_mh_grp[df50_mh_grp['model']==model][df50_mh_grp['att_module']==att][df50_mh_grp['num_heads']==n]['f1_micro_sk_ci_95'].reset_index(drop=True)[0]\n",
    "            \n",
    "            mh_macro_ub = mh_macro + mh_macro_95\n",
    "            mh_macro_lb = mh_macro - mh_macro_95\n",
    "\n",
    "            mh_micro_ub = mh_micro + mh_micro_95\n",
    "            mh_micro_lb = mh_micro - mh_micro_95\n",
    "            \n",
    "            \n",
    "            print(f'Single-Head Macro UB: {mh_macro_ub}')\n",
    "            print(f'Single-Head Macro LB: {mh_macro_lb}')\n",
    "\n",
    "            print(f'Single-Head Micro UB: {mh_micro_ub}')\n",
    "            print(f'Single-Head Micro LB: {mh_micro_lb}')\n",
    "    \n",
    "            \n",
    "            if (mh_macro_ub < sh_macro_lb) or (mh_macro_lb > sh_macro_ub):\n",
    "                macro_significance = True\n",
    "            else:\n",
    "                macro_significance = False\n",
    "            \n",
    "            if (mh_micro_ub < sh_micro_lb) or (mh_micro_lb > sh_micro_ub):\n",
    "                micro_significance = True\n",
    "            else:\n",
    "                micro_significance = False\n",
    "                \n",
    "            if mh_macro > sh_macro:\n",
    "                mh_larger_sh_macro = True\n",
    "            else:\n",
    "                mh_larger_sh_macro = False\n",
    "                \n",
    "            if mh_micro > sh_micro:\n",
    "                mh_larger_sh_micro = True\n",
    "            else:\n",
    "                mh_larger_sh_micro = False\n",
    "                        \n",
    "            # Append all the information\n",
    "            \n",
    "            model_col.append(model)\n",
    "            att_col.append(att)\n",
    "            nh_col.append(n)\n",
    "            macro_sig.append(macro_significance)\n",
    "            micro_sig.append(micro_significance)\n",
    "            macro_larger.append(mh_larger_sh_macro)\n",
    "            micro_larger.append(mh_larger_sh_micro)\n",
    "            \n",
    "            \n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "bcd99046",
   "metadata": {},
   "outputs": [],
   "source": [
    "d = {'models': model_col, 'atts': att_col,\n",
    "    'nh': nh_col, 'macro_sig': macro_sig, 'micro_sig': micro_sig,\n",
    "    'macro_larger': macro_larger, 'micro_larger': micro_larger}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "b9ca57f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sig = pd.DataFrame(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "3893d23e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>models</th>\n",
       "      <th>atts</th>\n",
       "      <th>nh</th>\n",
       "      <th>macro_sig</th>\n",
       "      <th>micro_sig</th>\n",
       "      <th>macro_larger</th>\n",
       "      <th>micro_larger</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>CNN</td>\n",
       "      <td>random</td>\n",
       "      <td>2</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>CNN</td>\n",
       "      <td>random</td>\n",
       "      <td>4</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>CNN</td>\n",
       "      <td>random</td>\n",
       "      <td>6</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>CNN</td>\n",
       "      <td>random</td>\n",
       "      <td>10</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>CNN</td>\n",
       "      <td>pretrained</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>CNN</td>\n",
       "      <td>pretrained</td>\n",
       "      <td>4</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>CNN</td>\n",
       "      <td>pretrained</td>\n",
       "      <td>6</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>CNN</td>\n",
       "      <td>pretrained</td>\n",
       "      <td>10</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>CNN</td>\n",
       "      <td>hierarchical_random</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>CNN</td>\n",
       "      <td>hierarchical_random</td>\n",
       "      <td>4</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>CNN</td>\n",
       "      <td>hierarchical_random</td>\n",
       "      <td>6</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>CNN</td>\n",
       "      <td>hierarchical_random</td>\n",
       "      <td>10</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>CNN</td>\n",
       "      <td>hierarchical_pretrained</td>\n",
       "      <td>2</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>CNN</td>\n",
       "      <td>hierarchical_pretrained</td>\n",
       "      <td>4</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>CNN</td>\n",
       "      <td>hierarchical_pretrained</td>\n",
       "      <td>6</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>CNN</td>\n",
       "      <td>hierarchical_pretrained</td>\n",
       "      <td>10</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>BiGRU</td>\n",
       "      <td>random</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>BiGRU</td>\n",
       "      <td>random</td>\n",
       "      <td>4</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>BiGRU</td>\n",
       "      <td>random</td>\n",
       "      <td>8</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>BiGRU</td>\n",
       "      <td>random</td>\n",
       "      <td>16</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>BiGRU</td>\n",
       "      <td>pretrained</td>\n",
       "      <td>2</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>BiGRU</td>\n",
       "      <td>pretrained</td>\n",
       "      <td>4</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>BiGRU</td>\n",
       "      <td>pretrained</td>\n",
       "      <td>8</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>BiGRU</td>\n",
       "      <td>pretrained</td>\n",
       "      <td>16</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>BiGRU</td>\n",
       "      <td>hierarchical_random</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>BiGRU</td>\n",
       "      <td>hierarchical_random</td>\n",
       "      <td>4</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>BiGRU</td>\n",
       "      <td>hierarchical_random</td>\n",
       "      <td>8</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>BiGRU</td>\n",
       "      <td>hierarchical_random</td>\n",
       "      <td>16</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>BiGRU</td>\n",
       "      <td>hierarchical_pretrained</td>\n",
       "      <td>2</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>BiGRU</td>\n",
       "      <td>hierarchical_pretrained</td>\n",
       "      <td>4</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>BiGRU</td>\n",
       "      <td>hierarchical_pretrained</td>\n",
       "      <td>8</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>BiGRU</td>\n",
       "      <td>hierarchical_pretrained</td>\n",
       "      <td>16</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>BiLSTM</td>\n",
       "      <td>random</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>BiLSTM</td>\n",
       "      <td>random</td>\n",
       "      <td>4</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>BiLSTM</td>\n",
       "      <td>random</td>\n",
       "      <td>8</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>BiLSTM</td>\n",
       "      <td>random</td>\n",
       "      <td>16</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>BiLSTM</td>\n",
       "      <td>pretrained</td>\n",
       "      <td>2</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>BiLSTM</td>\n",
       "      <td>pretrained</td>\n",
       "      <td>4</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>BiLSTM</td>\n",
       "      <td>pretrained</td>\n",
       "      <td>8</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>BiLSTM</td>\n",
       "      <td>pretrained</td>\n",
       "      <td>16</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>BiLSTM</td>\n",
       "      <td>hierarchical_random</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>BiLSTM</td>\n",
       "      <td>hierarchical_random</td>\n",
       "      <td>4</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>BiLSTM</td>\n",
       "      <td>hierarchical_random</td>\n",
       "      <td>8</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>BiLSTM</td>\n",
       "      <td>hierarchical_random</td>\n",
       "      <td>16</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>BiLSTM</td>\n",
       "      <td>hierarchical_pretrained</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>BiLSTM</td>\n",
       "      <td>hierarchical_pretrained</td>\n",
       "      <td>4</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>BiLSTM</td>\n",
       "      <td>hierarchical_pretrained</td>\n",
       "      <td>8</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>BiLSTM</td>\n",
       "      <td>hierarchical_pretrained</td>\n",
       "      <td>16</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>CLF</td>\n",
       "      <td>random</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>CLF</td>\n",
       "      <td>random</td>\n",
       "      <td>4</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>CLF</td>\n",
       "      <td>random</td>\n",
       "      <td>8</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>CLF</td>\n",
       "      <td>random</td>\n",
       "      <td>16</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>CLF</td>\n",
       "      <td>pretrained</td>\n",
       "      <td>2</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>CLF</td>\n",
       "      <td>pretrained</td>\n",
       "      <td>4</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>CLF</td>\n",
       "      <td>pretrained</td>\n",
       "      <td>8</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>CLF</td>\n",
       "      <td>pretrained</td>\n",
       "      <td>16</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>CLF</td>\n",
       "      <td>hierarchical_random</td>\n",
       "      <td>2</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>CLF</td>\n",
       "      <td>hierarchical_random</td>\n",
       "      <td>4</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>CLF</td>\n",
       "      <td>hierarchical_random</td>\n",
       "      <td>8</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>CLF</td>\n",
       "      <td>hierarchical_random</td>\n",
       "      <td>16</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>CLF</td>\n",
       "      <td>hierarchical_pretrained</td>\n",
       "      <td>2</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>CLF</td>\n",
       "      <td>hierarchical_pretrained</td>\n",
       "      <td>4</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>CLF</td>\n",
       "      <td>hierarchical_pretrained</td>\n",
       "      <td>8</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>CLF</td>\n",
       "      <td>hierarchical_pretrained</td>\n",
       "      <td>16</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    models                     atts  nh  macro_sig  micro_sig  macro_larger  \\\n",
       "0      CNN                   random   2      False      False         False   \n",
       "1      CNN                   random   4       True      False         False   \n",
       "2      CNN                   random   6       True      False         False   \n",
       "3      CNN                   random  10       True       True         False   \n",
       "4      CNN               pretrained   2       True       True          True   \n",
       "5      CNN               pretrained   4      False       True          True   \n",
       "6      CNN               pretrained   6      False      False          True   \n",
       "7      CNN               pretrained  10       True      False         False   \n",
       "8      CNN      hierarchical_random   2       True       True          True   \n",
       "9      CNN      hierarchical_random   4       True       True          True   \n",
       "10     CNN      hierarchical_random   6       True       True          True   \n",
       "11     CNN      hierarchical_random  10       True       True          True   \n",
       "12     CNN  hierarchical_pretrained   2      False       True          True   \n",
       "13     CNN  hierarchical_pretrained   4      False      False         False   \n",
       "14     CNN  hierarchical_pretrained   6      False      False         False   \n",
       "15     CNN  hierarchical_pretrained  10      False      False         False   \n",
       "16   BiGRU                   random   2       True       True          True   \n",
       "17   BiGRU                   random   4       True       True          True   \n",
       "18   BiGRU                   random   8      False      False          True   \n",
       "19   BiGRU                   random  16      False      False         False   \n",
       "20   BiGRU               pretrained   2      False      False         False   \n",
       "21   BiGRU               pretrained   4      False      False          True   \n",
       "22   BiGRU               pretrained   8      False      False          True   \n",
       "23   BiGRU               pretrained  16      False      False         False   \n",
       "24   BiGRU      hierarchical_random   2       True       True          True   \n",
       "25   BiGRU      hierarchical_random   4       True       True          True   \n",
       "26   BiGRU      hierarchical_random   8       True       True          True   \n",
       "27   BiGRU      hierarchical_random  16       True       True          True   \n",
       "28   BiGRU  hierarchical_pretrained   2      False       True         False   \n",
       "29   BiGRU  hierarchical_pretrained   4      False      False         False   \n",
       "30   BiGRU  hierarchical_pretrained   8      False      False         False   \n",
       "31   BiGRU  hierarchical_pretrained  16       True       True         False   \n",
       "32  BiLSTM                   random   2       True       True          True   \n",
       "33  BiLSTM                   random   4       True       True          True   \n",
       "34  BiLSTM                   random   8       True       True          True   \n",
       "35  BiLSTM                   random  16       True       True          True   \n",
       "36  BiLSTM               pretrained   2      False      False          True   \n",
       "37  BiLSTM               pretrained   4      False      False          True   \n",
       "38  BiLSTM               pretrained   8      False      False          True   \n",
       "39  BiLSTM               pretrained  16      False      False          True   \n",
       "40  BiLSTM      hierarchical_random   2       True       True          True   \n",
       "41  BiLSTM      hierarchical_random   4       True       True          True   \n",
       "42  BiLSTM      hierarchical_random   8       True       True          True   \n",
       "43  BiLSTM      hierarchical_random  16       True       True          True   \n",
       "44  BiLSTM  hierarchical_pretrained   2       True       True          True   \n",
       "45  BiLSTM  hierarchical_pretrained   4      False       True          True   \n",
       "46  BiLSTM  hierarchical_pretrained   8      False       True          True   \n",
       "47  BiLSTM  hierarchical_pretrained  16      False      False          True   \n",
       "48     CLF                   random   2       True       True          True   \n",
       "49     CLF                   random   4      False      False         False   \n",
       "50     CLF                   random   8      False      False         False   \n",
       "51     CLF                   random  16      False      False          True   \n",
       "52     CLF               pretrained   2      False      False         False   \n",
       "53     CLF               pretrained   4      False      False         False   \n",
       "54     CLF               pretrained   8      False      False         False   \n",
       "55     CLF               pretrained  16      False      False         False   \n",
       "56     CLF      hierarchical_random   2      False      False          True   \n",
       "57     CLF      hierarchical_random   4      False      False          True   \n",
       "58     CLF      hierarchical_random   8      False      False          True   \n",
       "59     CLF      hierarchical_random  16      False      False         False   \n",
       "60     CLF  hierarchical_pretrained   2      False      False          True   \n",
       "61     CLF  hierarchical_pretrained   4      False      False          True   \n",
       "62     CLF  hierarchical_pretrained   8      False      False         False   \n",
       "63     CLF  hierarchical_pretrained  16      False      False         False   \n",
       "\n",
       "    micro_larger  \n",
       "0           True  \n",
       "1          False  \n",
       "2          False  \n",
       "3          False  \n",
       "4           True  \n",
       "5           True  \n",
       "6           True  \n",
       "7          False  \n",
       "8           True  \n",
       "9           True  \n",
       "10          True  \n",
       "11          True  \n",
       "12          True  \n",
       "13          True  \n",
       "14         False  \n",
       "15         False  \n",
       "16          True  \n",
       "17          True  \n",
       "18         False  \n",
       "19         False  \n",
       "20         False  \n",
       "21          True  \n",
       "22          True  \n",
       "23         False  \n",
       "24          True  \n",
       "25          True  \n",
       "26          True  \n",
       "27          True  \n",
       "28         False  \n",
       "29         False  \n",
       "30         False  \n",
       "31         False  \n",
       "32          True  \n",
       "33          True  \n",
       "34          True  \n",
       "35          True  \n",
       "36          True  \n",
       "37          True  \n",
       "38          True  \n",
       "39          True  \n",
       "40          True  \n",
       "41          True  \n",
       "42          True  \n",
       "43          True  \n",
       "44          True  \n",
       "45          True  \n",
       "46          True  \n",
       "47          True  \n",
       "48          True  \n",
       "49         False  \n",
       "50         False  \n",
       "51          True  \n",
       "52          True  \n",
       "53         False  \n",
       "54         False  \n",
       "55         False  \n",
       "56          True  \n",
       "57          True  \n",
       "58          True  \n",
       "59         False  \n",
       "60          True  \n",
       "61          True  \n",
       "62         False  \n",
       "63         False  "
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_sig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8d0badf",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
