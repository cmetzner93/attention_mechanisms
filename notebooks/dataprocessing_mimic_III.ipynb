{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "027f3639",
   "metadata": {},
   "source": [
    "# Notebook that enables the preprocessing of the MIMIC-III dataset\n",
    "- How to execute preprocessing of clinical notes: Cell -> Run all\n",
    "- The utility functions can be found in folder: /src/tools/utils_preprocess.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c8352663",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Project root: /Users/cmetzner/Desktop/Study/PhD/research/ORNL/Biostatistics and Multiscale System Modeling/attention_mechanisms\n"
     ]
    }
   ],
   "source": [
    "# Built-in libraries\n",
    "import os\n",
    "import sys\n",
    "import pickle\n",
    "\n",
    "# warnings are switched since they are not important for preprocessing\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "try:\n",
    "    root = os.path.dirname(os.path.dirname(oa.path.abspath(__file__)))\n",
    "except NameError:\n",
    "    root = os.path.dirname(os.getcwd())\n",
    "sys.path.append(root)\n",
    "print('Project root: {}'.format(root))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "82a1e6ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /Users/cmetzner/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "# Installed libraries\n",
    "import pandas as pd\n",
    "\n",
    "# custom libraries\n",
    "from src.tools.utils_preprocess import rel2abs, preproc_clinical_notes\n",
    "from src.tools.utils_preprocess import create_splits, get_class_type\n",
    "#from src.tools.label_description import get_code_desc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4c01f84",
   "metadata": {},
   "source": [
    "# Define some constants\n",
    "\n",
    "Subsets:\n",
    "- 'full': Full set of available codes in MIMIC-III\n",
    "- '50': 50 most frequent codes in MIMIC-III"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "656f32ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "SEED = 42\n",
    "TRAIN_SIZE = 0.71\n",
    "TEST_SIZE = 0.52\n",
    "MIN_FREQ = 3\n",
    "\n",
    "subsets = ['MimicFull', 'Mimic50']\n",
    "splits = ['train', 'test', 'val']\n",
    "caml = True  # Use splits and preprocessing published by Mullenbach et al. 2018 (https://github.com/jamesmullenbach/caml-mimic)\n",
    "\n",
    "# Change paths to location of raw data (PROCEDURES_ICD.csv and DIAGNOSES_ICD.csv)\n",
    "path_data_raw = os.path.join(root, 'data', 'raw')\n",
    "# Change paths to location of processed data\n",
    "path_data_proc = os.path.join(root, 'data', 'processed')\n",
    "# Change paths to location where code descriptions are stored (CMS32_DESC_LONG_SHORT_DX.xlsx and CMS32_DESC_LONG_SHORT_SG.xlsx)\n",
    "path_data_external = os.path.join(root, 'data', 'external')\n",
    "\n",
    "\n",
    "# Create directories to store dataset specific data\n",
    "for subset in subsets:\n",
    "    if not os.path.exists(os.path.join(path_data_proc, f'data_{subset}/')):\n",
    "        os.makedirs(os.path.join(path_data_proc, f'data_{subset}/'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9819776a",
   "metadata": {},
   "source": [
    "# Preprocess ICD-9 Procedure/Diagnoses Codes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "54df3b7c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of procedure data: (240095, 5)\n",
      "Number of unique patient ids (SUBJECT_ID): 42214\n",
      "Number of unique hospital admission ids (HADM_ID): 52243\n",
      "Number of unique ICD-9 procedure codes: 2009\n",
      "Shape of diagnosis data: (651000, 5)\n",
      "Number of unique patient ids (SUBJECT_ID): 46517\n",
      "Number of unique hospital admission ids (HADM_ID): 58929\n",
      "Number of unique ICD-9 diagnosis codes: 6984\n",
      "\n",
      "Total number of ICD-9 codes in raw data of MIMIC-III: 8993\n"
     ]
    }
   ],
   "source": [
    "# Load ICD-9 procedure and diagnosis codes\n",
    "df_proc = pd.read_csv(os.path.join(path_data_raw, 'PROCEDURES_ICD.csv'))\n",
    "df_diag = pd.read_csv(os.path.join(path_data_raw, 'DIAGNOSES_ICD.csv'))\n",
    "\n",
    "# Remove all rows that have no ICD9-codes\n",
    "df_proc = df_proc[~df_proc['ICD9_CODE'].isna()]\n",
    "df_diag = df_diag[~df_diag['ICD9_CODE'].isna()]\n",
    "\n",
    "print(f'Shape of procedure data: {df_proc.shape}')\n",
    "print(f\"Number of unique patient ids (SUBJECT_ID): {df_proc.SUBJECT_ID.nunique()}\")\n",
    "print(f\"Number of unique hospital admission ids (HADM_ID): {df_proc.HADM_ID.nunique()}\")\n",
    "print(f\"Number of unique ICD-9 procedure codes: {df_proc.ICD9_CODE.nunique()}\")\n",
    "print(f'Shape of diagnosis data: {df_diag.shape}')\n",
    "print(f\"Number of unique patient ids (SUBJECT_ID): {df_diag.SUBJECT_ID.nunique()}\")\n",
    "print(f\"Number of unique hospital admission ids (HADM_ID): {df_diag.HADM_ID.nunique()}\")\n",
    "print(f\"Number of unique ICD-9 diagnosis codes: {df_diag.ICD9_CODE.nunique()}\")\n",
    "\n",
    "print(f'\\nTotal number of ICD-9 codes in raw data of MIMIC-III: {df_proc.ICD9_CODE.nunique() + df_diag.ICD9_CODE.nunique()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5d7335b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make sure ICD-9 codes are strings\n",
    "df_proc['ICD9_CODE'] = df_proc['ICD9_CODE'].astype(str)\n",
    "df_diag['ICD9_CODE'] = df_diag['ICD9_CODE'].astype(str)\n",
    "\n",
    "# Remove all whitespace\n",
    "df_proc['ICD9_CODE'] = df_proc.apply(lambda x: x.ICD9_CODE.strip(), axis=1)\n",
    "df_diag['ICD9_CODE'] = df_diag.apply(lambda x: x.ICD9_CODE.strip(), axis=1)\n",
    "\n",
    "# Transform relative ICD-9 code representation to absolute code\n",
    "df_proc['ABS_CODE'] = df_proc.apply(lambda x: rel2abs(x.ICD9_CODE, flag_proc=True), axis=1)\n",
    "df_diag['ABS_CODE'] = df_diag.apply(lambda x: rel2abs(x.ICD9_CODE, flag_proc=False), axis=1)\n",
    "\n",
    "df_proc['ICD9_TYPE'] = 'procedure'\n",
    "df_diag['ICD9_TYPE'] = 'diagnosis'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "552ef22f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Concat dataframes containing procedure and diagnosis codes\n",
    "df_codes = pd.concat([df_diag, df_proc])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7ee716e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save codes to csv file\n",
    "df_codes.to_csv(os.path.join(path_data_proc, 'ALL_CODES.csv'), index=False,\n",
    "                columns=['SUBJECT_ID', 'HADM_ID', 'ABS_CODE', 'ICD9_TYPE'],\n",
    "                header=['SUBJECT_ID', 'HADM_ID', 'ICD9_CODE', 'ICD9_TYPE'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d38fd4ff",
   "metadata": {},
   "source": [
    "## Check number of labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4f5a2cbe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SUBJECT_ID</th>\n",
       "      <th>HADM_ID</th>\n",
       "      <th>ICD9_CODE</th>\n",
       "      <th>ICD9_TYPE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>109</td>\n",
       "      <td>172335</td>\n",
       "      <td>403.01</td>\n",
       "      <td>diagnosis</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>109</td>\n",
       "      <td>172335</td>\n",
       "      <td>486</td>\n",
       "      <td>diagnosis</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>109</td>\n",
       "      <td>172335</td>\n",
       "      <td>582.81</td>\n",
       "      <td>diagnosis</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   SUBJECT_ID  HADM_ID ICD9_CODE  ICD9_TYPE\n",
       "0         109   172335    403.01  diagnosis\n",
       "1         109   172335       486  diagnosis\n",
       "2         109   172335    582.81  diagnosis"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "codes = pd.read_csv(os.path.join(path_data_proc, 'ALL_CODES.csv'), dtype={'ICD9_CODE': str})\n",
    "codes.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c48e2be1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8993"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Billable ICD-9 codes\n",
    "codes.ICD9_CODE.nunique()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9591e653",
   "metadata": {},
   "source": [
    "# Preprocess and tokenize clinical notes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6235359f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load clinical notes dataset\n",
    "notes = pd.read_csv(os.path.join(path_data_raw, 'NOTEEVENTS.csv'))\n",
    "notes = notes.loc[notes.CATEGORY == 'Discharge summary']\n",
    "notes = notes[['SUBJECT_ID', 'HADM_ID', 'TEXT']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "829c7b74",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7aa8351f8c3848a28e19f24eee4d01f0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/52726 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Preprocess clinical notes\n",
    "notes = preproc_clinical_notes(df_notes=notes, path_data_proc=path_data_proc, caml_clean=caml)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce3e9c8c",
   "metadata": {},
   "source": [
    "## Take a Look at the cleaned and tokenized clinical notes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0ea412b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "notes = pd.read_pickle(os.path.join(path_data_proc, 'CLEANED_NOTES.pkl'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "84e750c4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SUBJECT_ID</th>\n",
       "      <th>HADM_ID</th>\n",
       "      <th>TEXT</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>22532</td>\n",
       "      <td>167853.0</td>\n",
       "      <td>[admission, date, :, deidentified, discharge, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>13702</td>\n",
       "      <td>107527.0</td>\n",
       "      <td>[admission, date, :, deidentified, discharge, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>13702</td>\n",
       "      <td>167118.0</td>\n",
       "      <td>[admission, date, :, deidentified, discharge, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>13702</td>\n",
       "      <td>196489.0</td>\n",
       "      <td>[admission, date, :, deidentified, discharge, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>26880</td>\n",
       "      <td>135453.0</td>\n",
       "      <td>[admission, date, :, deidentified, discharge, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   SUBJECT_ID   HADM_ID                                               TEXT\n",
       "0       22532  167853.0  [admission, date, :, deidentified, discharge, ...\n",
       "1       13702  107527.0  [admission, date, :, deidentified, discharge, ...\n",
       "2       13702  167118.0  [admission, date, :, deidentified, discharge, ...\n",
       "3       13702  196489.0  [admission, date, :, deidentified, discharge, ...\n",
       "4       26880  135453.0  [admission, date, :, deidentified, discharge, ..."
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "notes.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "219c5cb3",
   "metadata": {},
   "source": [
    "# Combine Labels with Clinical Notes\n",
    "- Investigate all procedure codes that have just 2 positions and see if we can change them to a more meaningful version\n",
    "\n",
    "\n",
    "To-Do's\n",
    "- Split datasets into full, 50\n",
    "- Split SUBJECT_ID and HADM_ID into train, test, val - split is based on SUBJECT_ID --> Avoid data leakage\n",
    "- Retrieve categories (everything before the .)\n",
    "- Create X (map token2idx)\n",
    "- Retrieve list of labels BASED ON given DATASET\n",
    "- Create y (map codes and cats to multi-hot vectors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c268f5cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of hospital admission ids with clinical notes: 52726\n"
     ]
    }
   ],
   "source": [
    "# Number of hospital admissions with clinical notes\n",
    "print(f'Number of hospital admission ids with clinical notes: {notes.shape[0]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7d77c0fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of hospital admission ids that have codes and notes: 52722\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SUBJECT_ID</th>\n",
       "      <th>HADM_ID</th>\n",
       "      <th>TEXT</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>16238</th>\n",
       "      <td>13567</td>\n",
       "      <td>110220.0</td>\n",
       "      <td>[admission, date, :, deidentified, discharge, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21393</th>\n",
       "      <td>31866</td>\n",
       "      <td>182252.0</td>\n",
       "      <td>[admission, date, :, deidentified, discharge, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23115</th>\n",
       "      <td>24975</td>\n",
       "      <td>109963.0</td>\n",
       "      <td>[admission, date, :, deidentified, discharge, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32306</th>\n",
       "      <td>17796</td>\n",
       "      <td>142890.0</td>\n",
       "      <td>[admission, date, :, deidentified, discharge, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       SUBJECT_ID   HADM_ID                                               TEXT\n",
       "16238       13567  110220.0  [admission, date, :, deidentified, discharge, ...\n",
       "21393       31866  182252.0  [admission, date, :, deidentified, discharge, ...\n",
       "23115       24975  109963.0  [admission, date, :, deidentified, discharge, ...\n",
       "32306       17796  142890.0  [admission, date, :, deidentified, discharge, ..."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[110220.0, 182252.0, 109963.0, 142890.0]\n"
     ]
    }
   ],
   "source": [
    "# 1. Align HADM_IDS of codes and notes\n",
    "# Some HADM_ID have no codes but no notes\n",
    "# Some HADM_ID have notes but no codes (we already filtered out the HADM_ID without codes)\n",
    "\n",
    "# Get all hospital admission ids that have notes\n",
    "hadm_notes = notes.HADM_ID.unique().tolist()\n",
    "\n",
    "# Retrieve codes for those hospital admission ids\n",
    "codes = codes[codes['HADM_ID'].isin(hadm_notes)]\n",
    "\n",
    "# Check number of hospital admission id's in codes dataset\n",
    "print(f'Number of hospital admission ids that have codes and notes: {codes.HADM_ID.nunique()}')\n",
    "\n",
    "# Apparently, we have 4 hospital admission id's that have notes but no codes\n",
    "# Let's filter them out.\n",
    "# Get hospital admission ids with notes but are not included in the codes dataframe\n",
    "display(notes[~notes['HADM_ID'].isin(codes.HADM_ID.unique().tolist())])\n",
    "\n",
    "hadm_notes_wo_codes = notes[~notes['HADM_ID'].isin(codes.HADM_ID.unique().tolist())].HADM_ID.tolist()\n",
    "print(hadm_notes_wo_codes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5ce7c14a",
   "metadata": {},
   "outputs": [],
   "source": [
    "notes = notes[~notes['HADM_ID'].isin(hadm_notes_wo_codes)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e7748ac8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Check if number of HADM_IDs are equal in both dataframes.\n",
      "Codes == Notes : 52722 == 52722\n"
     ]
    }
   ],
   "source": [
    "# 1. Check if both dataframes have same number of hospital admission id's\n",
    "print('Check if number of HADM_IDs are equal in both dataframes.')\n",
    "print(f'Codes == Notes : {codes.HADM_ID.nunique()} == {notes.HADM_ID.nunique()}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e1e091c",
   "metadata": {},
   "source": [
    "# Create datasets for experiments by subsetting HADM_ID\n",
    "- full: \n",
    "- 50"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d711854",
   "metadata": {},
   "source": [
    "## Dataset: 'full' set of codes in MIMIC-III:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "8cc00b52",
   "metadata": {},
   "outputs": [],
   "source": [
    "codes_full = codes.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "4d1b91ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "l_codes_full = sorted(codes_full.ICD9_CODE.unique().tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "7bf7351c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of billable code labels: 8907\n"
     ]
    }
   ],
   "source": [
    "print(f'Number of billable code labels: {len(l_codes_full)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "2e16e579",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(os.path.join(path_data_proc, f'data_MimicFull', 'l_codes_MimicFull.pkl'), 'wb') as f:\n",
    "    pickle.dump(l_codes_full, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "99a8525e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aggregate individual label mentions in lists\n",
    "codes_full = codes_full.groupby(['SUBJECT_ID', 'HADM_ID']).agg({'ICD9_CODE': list}).reset_index()\n",
    "\n",
    "# Remove redundant labels in lists\n",
    "codes_full['ICD9_CODE'] = codes_full.apply(lambda x: sorted(list(set(x.ICD9_CODE))), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "5fcfcdf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate full dataset\n",
    "df_full = codes_full.merge(notes, how='left', on=['SUBJECT_ID', 'HADM_ID']).sort_values(['SUBJECT_ID', 'HADM_ID'])\n",
    "\n",
    "# Save dataset\n",
    "df_full.to_pickle(os.path.join(path_data_proc, 'data_MimicFull', 'DATA_MimicFull.pkl'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4649cc7",
   "metadata": {},
   "source": [
    "## Dataset: n='50' most frequent in MIMIC-III:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "5bfb5b14",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['038.9',\n",
       " '244.9',\n",
       " '250.00',\n",
       " '272.0',\n",
       " '272.4',\n",
       " '276.1',\n",
       " '276.2',\n",
       " '285.1',\n",
       " '285.9',\n",
       " '287.5',\n",
       " '305.1',\n",
       " '311',\n",
       " '33.24',\n",
       " '36.15',\n",
       " '37.22',\n",
       " '38.91',\n",
       " '38.93',\n",
       " '39.61',\n",
       " '39.95',\n",
       " '401.9',\n",
       " '403.90',\n",
       " '410.71',\n",
       " '412',\n",
       " '414.01',\n",
       " '424.0',\n",
       " '427.31',\n",
       " '428.0',\n",
       " '45.13',\n",
       " '486',\n",
       " '496',\n",
       " '507.0',\n",
       " '511.9',\n",
       " '518.81',\n",
       " '530.81',\n",
       " '584.9',\n",
       " '585.9',\n",
       " '599.0',\n",
       " '88.56',\n",
       " '88.72',\n",
       " '93.90',\n",
       " '96.04',\n",
       " '96.6',\n",
       " '96.71',\n",
       " '96.72',\n",
       " '99.04',\n",
       " '99.15',\n",
       " '995.92',\n",
       " 'V15.82',\n",
       " 'V45.81',\n",
       " 'V58.61']"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n = 50\n",
    "# Retrieve the 50 most frequent codes in MIMIC-III\n",
    "most_50 = sorted(codes.ICD9_CODE.value_counts()[:n].index.tolist())\n",
    "most_50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "1650d31a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Subset codes dataset\n",
    "codes_50 = codes.copy()\n",
    "codes_50 = codes_50[codes_50['ICD9_CODE'].isin(most_50)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "e957d04a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of billable code labels: 50\n"
     ]
    }
   ],
   "source": [
    "# Get list with labels\n",
    "l_codes_50 = sorted(codes_50.ICD9_CODE.unique().tolist())\n",
    "print(f'Number of billable code labels: {len(l_codes_50)}')\n",
    "\n",
    "# Save\n",
    "with open(os.path.join(path_data_proc, 'data_Mimic50', 'l_codes_Mimic50.pkl'), 'wb') as f:\n",
    "    pickle.dump(l_codes_50, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "6e4c8414",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aggregate individual label mentions in lists\n",
    "codes_50 = codes_50.groupby(['SUBJECT_ID', 'HADM_ID']).agg({'ICD9_CODE': list}).reset_index()\n",
    "\n",
    "# Remove redundant labels in lists\n",
    "codes_50['ICD9_CODE'] = codes_50.apply(lambda x: sorted(list(set(x.ICD9_CODE))), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "2fb83668",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate full dataset\n",
    "df_50 = codes_50.merge(notes, how='left', on=['SUBJECT_ID', 'HADM_ID']).sort_values(['SUBJECT_ID', 'HADM_ID'])\n",
    "\n",
    "# Save dataset\n",
    "df_50.to_pickle(os.path.join(path_data_proc, 'data_Mimic50', 'DATA_Mimic50.pkl'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfe2f9eb",
   "metadata": {},
   "source": [
    "# Generate training/testing/validation splits (X and y samples)\n",
    "In this segment we are splitting the four individual datasets into training/testing/validation sets using the patient ids (SUBJECT_ID) and HADM_ID. By using SUBJECT_ID we are avoiding data leackage from one split to another, i.e., one distinct patient only occurs in either one of those splits.\n",
    "\n",
    "For sake of reproducibility, for the `full` and `50` datasets we are using the published HADM_ID's proposed by Mullenbach et al. 2018, since a plethora of published work used them as the foundation (source: https://github.com/jamesmullenbach/caml-mimic/tree/master/mimicdata/mimic3)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "1e7cfa4a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Current subset: MimicFull\n",
      "Current split: train\n",
      "Vocab size for train: 120481\n",
      "Current split: test\n",
      "Current split: val\n",
      "\n",
      "Current subset: Mimic50\n",
      "Current split: train\n",
      "Vocab size for train: 50176\n",
      "Current split: test\n",
      "Current split: val\n"
     ]
    }
   ],
   "source": [
    "for subset in subsets:\n",
    "    create_splits(subset=subset, path_data_proc=path_data_proc, min_freq=MIN_FREQ)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81903e9f",
   "metadata": {},
   "source": [
    "# Get Code Descriptions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2402cd2",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#for subset in subsets:            \n",
    "#    get_code_desc(path_data_external=path_data_external, path_data_processed=path_data_proc, subset=subset)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
